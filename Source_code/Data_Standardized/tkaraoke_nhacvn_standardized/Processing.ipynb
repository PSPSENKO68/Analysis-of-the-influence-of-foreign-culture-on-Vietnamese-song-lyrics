{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebe9089950930b0b",
   "metadata": {},
   "source": [
    "Import th∆∞ vi·ªán c·∫ßn thi·∫øt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "413e05e5575719b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T06:13:04.676094Z",
     "start_time": "2025-10-25T06:13:04.672263Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from langdetect import detect, LangDetectException\n",
    "import ast\n",
    "import csv\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from urllib.parse import quote\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import logging\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import google.generativeai as genai\n",
    "from tqdm import tqdm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593a8df2076260f0",
   "metadata": {},
   "source": [
    "- T·∫°o l·∫°i c·∫•u tr√∫c chu·∫©n cho 2 file\n",
    "    - File Nhacvn: path: \"normalize_Nhacvn_output.csv\" t·ª´ {urls,title,artist,composer,genre,lyrics} ==> {title ,composers, lyricists, year, genres, lyrics, urls, source, note} , c·ªôt kh√¥ng c√≥ th√¨ ƒë·ªÉ l√† Null\n",
    "    - File tkaraoke : path:\"normalize_tkaraoke_output.csv\" t·ª´ {urls,title,artist,lyrics} ==> {title ,composers, lyricists, year, genres, lyrics, urls, source, note} , c·ªôt kh√¥ng c√≥ th√¨ ƒë·ªÉ tr·ªëng ho·∫∑c null t√πy theo ki·ªÉu d·ªØ li·ªáu\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d30f38a6b72f47",
   "metadata": {},
   "source": [
    "# NHACVN chuan hoa c·∫•u tr√∫c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ba1729eb0ceac4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T19:37:22.078454Z",
     "start_time": "2025-10-23T19:37:16.199719Z"
    }
   },
   "outputs": [],
   "source": [
    "# === ƒê·ªçc file g·ªëc ===\n",
    "df = pd.read_csv(\"normalize_Nhacvn_output.csv\")\n",
    "\n",
    "# === H√†m ti·ªán √≠ch ƒë·ªÉ chu·∫©n h√≥a d·∫°ng list ===\n",
    "def ensure_list(x):\n",
    "    if pd.isna(x) or x == \"Null\":\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return [str(v).strip() for v in x if str(v).strip()]\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            val = ast.literal_eval(x)\n",
    "            if isinstance(val, list):\n",
    "                return [str(v).strip() for v in val if str(v).strip()]\n",
    "        except:\n",
    "            return [v.strip() for v in x.split(\",\") if v.strip()]\n",
    "    return [str(x).strip()]\n",
    "\n",
    "# === T·∫°o dataframe m·ªõi theo schema chu·∫©n ===\n",
    "df_new = pd.DataFrame({\n",
    "    \"title\": df.get(\"title\", pd.Series([\"\"] * len(df))),\n",
    "    \"composers\": df.get(\"composer\", pd.Series([\"\"] * len(df))).apply(ensure_list),\n",
    "    \"lyricists\": pd.Series([[]] * len(df)),     # kh√¥ng c√≥ trong Nhacvn\n",
    "    \"year\": pd.Series([None] * len(df)),        # ch∆∞a c√≥ d·ªØ li·ªáu nƒÉm\n",
    "    \"genres\": df.get(\"genre\", pd.Series([\"\"] * len(df))).apply(ensure_list),\n",
    "    \"lyrics\": df.get(\"lyrics\", pd.Series([\"\"] * len(df))),\n",
    "    \"urls\": df.get(\"urls\", pd.Series([\"\"] * len(df))).apply(ensure_list),\n",
    "    \"source\": pd.Series([\"\"] * len(df)),        # tr·ªëng theo ki·ªÉu text\n",
    "    \"note\": pd.Series([\"\"] * len(df))           # tr·ªëng theo ki·ªÉu text\n",
    "})\n",
    "\n",
    "# === Xu·∫•t ra CSV & JSON ===\n",
    "df_new.to_csv(\"normalized_Nhacvn_standard.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3b70649037676d",
   "metadata": {},
   "source": [
    "# CHUAN HOA CAU TRUC tkaraoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd51d76de35a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "\n",
    "# === ƒê·ªçc file g·ªëc ===\n",
    "df = pd.read_csv(\"normalize_tkaraoke_output.csv\")\n",
    "\n",
    "def ensure_list(x):\n",
    "    if pd.isna(x) or x == \"Null\":\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return [str(v).strip() for v in x if str(v).strip()]\n",
    "    if isinstance(x, str):\n",
    "        # n·∫øu l√† chu·ªói ch·ª©a list literal, th·ª≠ parse\n",
    "        try:\n",
    "            import ast\n",
    "            val = ast.literal_eval(x)\n",
    "            if isinstance(val, list):\n",
    "                return [str(v).strip() for v in val if str(v).strip()]\n",
    "        except:\n",
    "            return [v.strip() for v in x.split(\",\") if v.strip()]\n",
    "    return [str(x).strip()]\n",
    "\n",
    "def extract_authors(text):\n",
    "    \"\"\"\n",
    "    Tr·∫£ v·ªÅ (composers:list[str], lyricists:list[str])\n",
    "    - X·ª≠ l√Ω c√°c d·∫°ng: \"T√°c gi·∫£:Nh·∫°cDBaola&JustaTee, l·ªùiJustaTee\"\n",
    "    - Ho·∫°t ƒë·ªông v·ªõi \"Nh·∫°c\", \"L·ªùi\", \"Th∆°\" vi·∫øt d√≠nh ho·∫∑c c√°ch\n",
    "    - T√°ch theo ',', '&', ho·∫∑c t·ª´ 'v√†' (word boundary)\n",
    "    - Gi·ªØ unique trong t·ª´ng danh s√°ch nh∆∞ng KH√îNG lo·∫°i t√™n gi·ªØa 2 role\n",
    "    \"\"\"\n",
    "    composers, lyricists = [], []\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return [], []\n",
    "\n",
    "    # 1) lo·∫°i prefix\n",
    "    t = text.replace(\"T√°c gi·∫£:\", \"\").strip()\n",
    "\n",
    "    # 2) x√≥a k√Ω t·ª± ·∫©n n·∫øu c√≥\n",
    "    t = re.sub(r'[\\u200B-\\u200D\\uFEFF\\u00A0]', '', t)\n",
    "\n",
    "    # 3) th√™m d·∫•u c√°ch khi 'Nh·∫°c'/'L·ªùi'/'Th∆°' d√≠nh li·ªÅn v·ªõi t√™n (v√≠ d·ª• \"Nh·∫°cDBaola\")\n",
    "    t = re.sub(r'(?i)(Nh·∫°c|L·ªùi|Th∆°)(?=[^\\s:])', r'\\1 ', t)\n",
    "\n",
    "    # 4) chu·∫©n h√≥a kho·∫£ng tr·∫Øng\n",
    "    t = re.sub(r'\\s+', ' ', t).strip()\n",
    "\n",
    "    # 5) t√¨m t·∫•t c·∫£ kh·ªëi \"Nh·∫°c ...\", \"L·ªùi ...\", \"Th∆° ...\" (m·ªói kh·ªëi k√©o t·ªõi tr∆∞·ªõc keyword ti·∫øp theo ho·∫∑c t·ªõi EOL)\n",
    "    pattern = re.compile(r'(?i)(Nh·∫°c|L·ªùi|Th∆°)\\s*:?\\s*(.*?)(?=(?:Nh·∫°c|L·ªùi|Th∆°|$))', flags=re.IGNORECASE)\n",
    "    matches = list(pattern.finditer(t))\n",
    "\n",
    "    split_re = re.compile(r'\\s*(?:,|&|\\bv√†\\b)\\s*', flags=re.IGNORECASE)\n",
    "\n",
    "    if matches:\n",
    "        for m in matches:\n",
    "            role = m.group(1).strip().lower()\n",
    "            names_raw = m.group(2).strip()\n",
    "            # t√°ch theo , & v√† t·ª´ 'v√†' (word-boundary)\n",
    "            names = [n.strip() for n in split_re.split(names_raw) if n.strip()]\n",
    "            # chu·∫©n h√≥a t√™n (lo·∫°i kho·∫£ng tr·∫Øng th·ª´a)\n",
    "            names = [n for n in names if n]\n",
    "            # title-case t√™n (tu·ª≥ b·∫°n, c√≥ th·ªÉ b·ªè .title() n·∫øu mu·ªën gi·ªØ nguy√™n)\n",
    "            names = [n.strip() for n in names]\n",
    "            if role.startswith('nh·∫°c'):\n",
    "                composers.extend(names)\n",
    "            else:  # 'l·ªùi' ho·∫∑c 'th∆°' -> lyricists\n",
    "                lyricists.extend(names)\n",
    "    else:\n",
    "        # kh√¥ng th·∫•y keyword -> coi to√†n b·ªô l√†m composers, t√°ch theo separators\n",
    "        names = [n.strip() for n in split_re.split(t) if n.strip()]\n",
    "        composers.extend(names)\n",
    "\n",
    "    # unique t·ª´ng list, gi·ªØ th·ª© t·ª± xu·∫•t hi·ªán\n",
    "    def unique_preserve_order(seq):\n",
    "        seen = set()\n",
    "        out = []\n",
    "        for x in seq:\n",
    "            key = x.strip()\n",
    "            if key and key not in seen:\n",
    "                seen.add(key)\n",
    "                out.append(key)\n",
    "        return out\n",
    "\n",
    "    composers = unique_preserve_order(composers)\n",
    "    lyricists = unique_preserve_order(lyricists)\n",
    "\n",
    "    return composers, lyricists\n",
    "\n",
    "\n",
    "# === T·∫°o c·∫•u tr√∫c d·ªØ li·ªáu chu·∫©n ===\n",
    "records = []\n",
    "for _, row in df.iterrows():\n",
    "    composers, lyricists = extract_authors(row.get(\"artist\", \"\"))\n",
    "    urls = ensure_list(row.get(\"urls\", \"\"))\n",
    "\n",
    "    records.append({\n",
    "        \"title\": row.get(\"title\", \"\").strip(),\n",
    "        \"composers\": composers,\n",
    "        \"lyricists\": lyricists,\n",
    "        \"year\": None,\n",
    "        \"genres\": [],\n",
    "        \"lyrics\": row.get(\"lyrics\", \"\"),\n",
    "        \"urls\": urls,\n",
    "        \"source\": None,  # ƒë·ªÉ null\n",
    "        \"note\": \"\"\n",
    "    })\n",
    "\n",
    "df_new = pd.DataFrame(records)\n",
    "\n",
    "# === Xu·∫•t ra file ===\n",
    "df_new.to_csv(\"normalized_tkaraoke_standard_2.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"‚úÖ ƒê√£ chu·∫©n h√≥a file 'normalize_tkaraoke_output.csv'\")\n",
    "print(df_new[[\"title\", \"composers\", \"lyricists\"]].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8dfc9cff29a0f25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T20:29:42.570509Z",
     "start_time": "2025-10-23T20:29:35.320916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ chu·∫©n h√≥a file 'normalize_tkaraoke_output.csv'\n",
      "                                          title              composers  \\\n",
      "0                              ƒê·∫Øp M·ªô Cu·ªôc T√¨nh             [V≈© Thanh]   \n",
      "1                                  B√†i H√°t Xu√¢n       [Tr·∫ßn Thanh S∆°n]   \n",
      "2                              T√¨nh ∆†i H·ª°i T√¨nh         [Eric L√™ Ph√∫c]   \n",
      "3                                  Em Kh√¥ng Th·ªÉ  [Touliver, Ti√™n Ti√™n]   \n",
      "4  V·ªÅ ƒê√¢u M√°i T√≥c Ng∆∞·ªùi Th∆∞∆°ng (Y√™u L√†n T√≥c ·∫§y)            [Ho√†i Linh]   \n",
      "\n",
      "            lyricists  \n",
      "0                  []  \n",
      "1                  []  \n",
      "2  [Nguy·ªÖn T·∫•t Nhi√™n]  \n",
      "3         [Ti√™n Ti√™n]  \n",
      "4                  []  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "\n",
    "# === ƒê·ªçc file g·ªëc ===\n",
    "df = pd.read_csv(\"normalize_tkaraoke_output.csv\")\n",
    "\n",
    "def ensure_list(x):\n",
    "    if pd.isna(x) or x == \"Null\":\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return [str(v).strip() for v in x if str(v).strip()]\n",
    "    if isinstance(x, str):\n",
    "        # n·∫øu l√† chu·ªói ch·ª©a list literal, th·ª≠ parse\n",
    "        try:\n",
    "            import ast\n",
    "            val = ast.literal_eval(x)\n",
    "            if isinstance(val, list):\n",
    "                return [str(v).strip() for v in val if str(v).strip()]\n",
    "        except:\n",
    "            return [v.strip() for v in x.split(\",\") if v.strip()]\n",
    "    return [str(x).strip()]\n",
    "\n",
    "def extract_authors(text):\n",
    "    \"\"\"\n",
    "    Tr·∫£ v·ªÅ (composers:list[str], lyricists:list[str])\n",
    "    - X·ª≠ l√Ω ƒë∆∞·ª£c c·∫£ d·∫°ng:\n",
    "        \"T√°c gi·∫£:Nh·∫°cAnh B·∫±ng, th∆°Th√°i Can\"\n",
    "        \"T√°c gi·∫£:Nh·∫°cNguy·ªÖn Hi·ªÅn, l·ªùiKim Tu·∫•n\"\n",
    "        \"T√°c gi·∫£:Ho√†ng Thi Th∆°\"\n",
    "    - Nh·∫≠n di·ªán Nh·∫°c/L·ªùi/Th∆° d√≠nh li·ªÅn ho·∫∑c c√≥ d·∫•u c√°ch\n",
    "    - Kh√¥ng nh·∫ßm 'Th∆°' trong t√™n ng∆∞·ªùi\n",
    "    \"\"\"\n",
    "    composers, lyricists = [], []\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return [], []\n",
    "\n",
    "    # 1. B·ªè prefix\n",
    "    t = text.replace(\"T√°c gi·∫£:\", \"\").strip()\n",
    "\n",
    "    # 2. Lo·∫°i k√Ω t·ª± ·∫©n\n",
    "    t = re.sub(r'[\\u200B-\\u200D\\uFEFF\\u00A0]', '', t)\n",
    "\n",
    "    # 3. Th√™m kho·∫£ng tr·∫Øng sau c√°c vai tr√≤ n·∫øu d√≠nh li·ªÅn (vd: 'Nh·∫°cAnh B·∫±ng' -> 'Nh·∫°c Anh B·∫±ng')\n",
    "    t = re.sub(r'(?i)(Nh·∫°c|L·ªùi|Th∆°)(?=[A-Z√Ä-·ª¥a-z√†-·ªπ])', r'\\1 ', t)\n",
    "\n",
    "    # 4. Chu·∫©n h√≥a kho·∫£ng tr·∫Øng\n",
    "    t = re.sub(r'\\s+', ' ', t).strip()\n",
    "\n",
    "    # 5. Regex nh·∫≠n di·ªán kh·ªëi vai tr√≤\n",
    "    # - C√≥ th·ªÉ c√≥ d·∫•u ':' ho·∫∑c kh√¥ng\n",
    "    # - Gi·ªõi h·∫°n vai tr√≤ ch·ªâ match khi ƒë·ª©ng ƒë·∫ßu ho·∫∑c sau d·∫•u ',' ho·∫∑c '&'\n",
    "    pattern = re.compile(r'(?i)\\b(Nh·∫°c|L·ªùi|Th∆°)\\b\\s*:?\\s*(.*?)(?=(?:\\bNh·∫°c\\b|\\bL·ªùi\\b|\\bTh∆°\\b|$))')\n",
    "\n",
    "    matches = list(pattern.finditer(t))\n",
    "    split_re = re.compile(r'\\s*(?:,|&|\\bv√†\\b)\\s*', flags=re.IGNORECASE)\n",
    "\n",
    "    if matches:\n",
    "        for m in matches:\n",
    "            role = m.group(1).strip().lower()\n",
    "            names_raw = m.group(2).strip()\n",
    "            names = [n.strip() for n in split_re.split(names_raw) if n.strip()]\n",
    "            if role.startswith('nh·∫°c'):\n",
    "                composers.extend(names)\n",
    "            else:\n",
    "                lyricists.extend(names)\n",
    "    else:\n",
    "        # kh√¥ng c√≥ vai tr√≤ -> to√†n b·ªô l√† composer\n",
    "        names = [n.strip() for n in split_re.split(t) if n.strip()]\n",
    "        composers.extend(names)\n",
    "\n",
    "    # Lo·∫°i tr√πng, gi·ªØ th·ª© t·ª±\n",
    "    def unique(seq):\n",
    "        seen, out = set(), []\n",
    "        for x in seq:\n",
    "            if x not in seen and x:\n",
    "                seen.add(x)\n",
    "                out.append(x)\n",
    "        return out\n",
    "\n",
    "    return unique(composers), unique(lyricists)\n",
    "\n",
    "\n",
    "\n",
    "# === T·∫°o c·∫•u tr√∫c d·ªØ li·ªáu chu·∫©n ===\n",
    "records = []\n",
    "for _, row in df.iterrows():\n",
    "    composers, lyricists = extract_authors(row.get(\"artist\", \"\"))\n",
    "    urls = ensure_list(row.get(\"urls\", \"\"))\n",
    "\n",
    "    records.append({\n",
    "        \"title\": row.get(\"title\", \"\").strip(),\n",
    "        \"composers\": composers,\n",
    "        \"lyricists\": lyricists,\n",
    "        \"year\": None,\n",
    "        \"genres\": [],\n",
    "        \"lyrics\": row.get(\"lyrics\", \"\"),\n",
    "        \"urls\": urls,\n",
    "        \"source\": None,  # ƒë·ªÉ null\n",
    "        \"note\": \"\"\n",
    "    })\n",
    "\n",
    "df_new = pd.DataFrame(records)\n",
    "\n",
    "# === Xu·∫•t ra file ===\n",
    "df_new.to_csv(\"normalized_tkaraoke_standard_2.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"‚úÖ ƒê√£ chu·∫©n h√≥a file 'normalize_tkaraoke_output.csv'\")\n",
    "print(df_new[[\"title\", \"composers\", \"lyricists\"]].head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39343270fa02c2c",
   "metadata": {},
   "source": [
    "# chu·∫©n h√≥a t·ª´ng c·ªôt theo y√™u c·∫ßu : NHACVN v√† tkaraoke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a367e459550969",
   "metadata": {},
   "source": [
    "C·ªòT TITLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da141c92006e3bb9",
   "metadata": {},
   "source": [
    "Quy chuan cho ten bai hat ·ªü cot text:\n",
    "tat ca cac ki tu viet thuong\n",
    "khong co dau dac biet va dau cach & dau va cuoi\n",
    "giua nhung chu chi co 1 dau cach\n",
    "thay dau & bang chu va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b2e90be4ab91e90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T08:47:37.769146Z",
     "start_time": "2025-10-23T08:47:34.906683Z"
    }
   },
   "outputs": [],
   "source": [
    "# ƒê·ªçc file CSV\n",
    "df = pd.read_csv(\"normalized_tkaraoke_standard.csv\")\n",
    "\n",
    "# H√†m chu·∫©n h√≥a ti√™u ƒë·ªÅ b√†i h√°t\n",
    "def normalize_title(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    text = text.lower()                              # 1. Vi·∫øt th∆∞·ªùng\n",
    "    text = text.replace('&', ' v√† ')                  # 2. Thay & ‚Üí v√†\n",
    "    text = re.sub(r'[^\\w\\s]', '', text, flags=re.UNICODE)  # 3. Gi·ªØ l·∫°i ch·ªØ c√°i c√≥ d·∫•u v√† s·ªë\n",
    "    text = re.sub(r'\\s+', ' ', text)                  # 4. Ch·ªâ 1 kho·∫£ng tr·∫Øng gi·ªØa c√°c t·ª´\n",
    "    text = text.strip()                               # 5. B·ªè kho·∫£ng tr·∫Øng ƒë·∫ßu/cu·ªëi\n",
    "    return text\n",
    "\n",
    "# √Åp d·ª•ng cho c·ªôt title\n",
    "df['title'] = df['title'].apply(normalize_title)\n",
    "\n",
    "# Ghi ƒë√® ho·∫∑c l∆∞u file m·ªõi\n",
    "df.to_csv(\"normalized_tkaraoke_standard_clean.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93067cd1368633ae",
   "metadata": {},
   "source": [
    "## ƒê·∫æM S·ªê D√íNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ee6d8f0877c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\n",
    "    \"normalized_Nhacvn_standard.csv\",\n",
    "    \"normalized_Nhacvn_standard_clean.csv\",\n",
    "    \"normalized_tkaraoke_standard.csv\",\n",
    "    \"normalized_tkaraoke_standard_clean.csv\"\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"Counting lines for the following CSV files:\")\n",
    "for filename in file_list:\n",
    "    try:\n",
    "        # M·ªü t·ªáp v√† ƒë·∫øm s·ªë d√≤ng hi·ªáu qu·∫£\n",
    "        with open(filename, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            line_count = sum(1 for line in f)\n",
    "        results[filename] = line_count\n",
    "        print(f\"- {filename}: {line_count} lines\")\n",
    "    except FileNotFoundError:\n",
    "        results[filename] = \"File not found\"\n",
    "        print(f\"- {filename}: File not found (L·ªói: Kh√¥ng t√¨m th·∫•y t·ªáp)\")\n",
    "    except Exception as e:\n",
    "        results[filename] = f\"Error: {e}\"\n",
    "        print(f\"- {filename}: Error occurred: {e} (L·ªói x·∫£y ra: {e})\")\n",
    "\n",
    "print(\"\\n--- Summary (T√≥m t·∫Øt) ---\")\n",
    "for filename, count in results.items():\n",
    "    print(f\"{filename}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2842f8f236838f",
   "metadata": {},
   "source": [
    "# CHU·∫®N H√ìA C·ªòT LYRICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2005543166319918",
   "metadata": {},
   "source": [
    "## NHACVN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a90e93af9548ea1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T10:21:48.046939Z",
     "start_time": "2025-10-23T10:21:33.936026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ chu·∫©n h√≥a lyrics (bao g·ªìm x√≥a 'ƒêK:') & l∆∞u t·∫°i 'done_lyrics_nhacvn.csv'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def clean_lyrics(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # 1Ô∏è‚É£ X√≥a k√Ω t·ª± ·∫©n nh∆∞ ZWNBSP, NBSP, BOM\n",
    "    text = re.sub(r'[\\u200B-\\u200D\\uFEFF\\u00A0]', '', text)\n",
    "\n",
    "    # 2Ô∏è‚É£ X√≥a s·ªë th·ª© t·ª± ki·ªÉu \"1. \", \"23. \"\n",
    "    text = re.sub(r'(^|\\s)\\d+\\.\\s*', r'\\1', text)\n",
    "\n",
    "    # 3Ô∏è‚É£ X√≥a ch·ªâ d·∫´n gi·ªçng h√°t v√† ƒëi·ªáp kh√∫c\n",
    "    text = re.sub(\n",
    "        r'\\b(gi·ªçng\\s*nam|gi·ªçng\\s*n·ªØ|nam|n·ªØ|ƒëk|ƒëi·ªáp\\s*kh√∫c)\\s*:\\s*',\n",
    "        '',\n",
    "        text,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # 4Ô∏è‚É£ X√≥a to√†n b·ªô n·ªôi dung trong ngo·∫∑c tr√≤n, ngo·∫∑c vu√¥ng n·∫øu c√≥\n",
    "    text = re.sub(r'[\\(\\[].*?[\\)\\]]', '', text)\n",
    "\n",
    "    # 5Ô∏è‚É£ Thay d·∫•u & b·∫±ng ch·ªØ \"v√†\"\n",
    "    text = text.replace('&', 'v√†')\n",
    "\n",
    "    # 6Ô∏è‚É£ Chuy·ªÉn to√†n b·ªô sang ch·ªØ th∆∞·ªùng\n",
    "    text = text.lower()\n",
    "\n",
    "    # 7Ô∏è‚É£ Gi·ªØ l·∫°i ch·ªØ c√°i, s·ªë, kho·∫£ng tr·∫Øng **v√† d·∫•u ph·∫©y**\n",
    "    text = re.sub(r'[^a-z√†√°·∫£√£·∫°ƒÉ·∫±·∫Ø·∫≥·∫µ·∫∑√¢·∫ß·∫•·∫©·∫´·∫≠√®√©·∫ª·∫Ω·∫π√™·ªÅ·∫ø·ªÉ·ªÖ·ªá'\n",
    "                  r'√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªì·ªë·ªï·ªó·ªô∆°·ªù·ªõ·ªü·ª°·ª£'\n",
    "                  r'√π√∫·ªß≈©·ª•∆∞·ª´·ª©·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµƒë0-9,\\s]', '', text)\n",
    "\n",
    "    # 8Ô∏è‚É£ Chu·∫©n h√≥a kho·∫£ng tr·∫Øng\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# === Ch·∫°y x·ª≠ l√Ω ===\n",
    "df = pd.read_csv('normalized_Nhacvn_standard_clean.csv')\n",
    "\n",
    "df['lyrics'] = df['lyrics'].astype(str).apply(clean_lyrics)\n",
    "\n",
    "# L∆∞u k·∫øt qu·∫£\n",
    "output_path = 'done_lyrics_nhacvn.csv'\n",
    "df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"‚úÖ ƒê√£ chu·∫©n h√≥a lyrics (bao g·ªìm x√≥a 'ƒêK:') & l∆∞u t·∫°i '{output_path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14882a3c15d619c2",
   "metadata": {},
   "source": [
    "### TKARAOKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "293fac12ae132782",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T10:22:19.026129Z",
     "start_time": "2025-10-23T10:22:08.704827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ chu·∫©n h√≥a lyrics (bao g·ªìm x√≥a 'ƒêK:') & l∆∞u t·∫°i 'done_tkaraoke_nhacvn.csv'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def clean_lyrics(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # 1Ô∏è‚É£ X√≥a k√Ω t·ª± ·∫©n nh∆∞ ZWNBSP, NBSP, BOM\n",
    "    text = re.sub(r'[\\u200B-\\u200D\\uFEFF\\u00A0]', '', text)\n",
    "\n",
    "    # 2Ô∏è‚É£ X√≥a s·ªë th·ª© t·ª± ki·ªÉu \"1. \", \"23. \"\n",
    "    text = re.sub(r'(^|\\s)\\d+\\.\\s*', r'\\1', text)\n",
    "\n",
    "    # 3Ô∏è‚É£ X√≥a ch·ªâ d·∫´n gi·ªçng h√°t v√† ƒëi·ªáp kh√∫c\n",
    "    text = re.sub(\n",
    "        r'\\b(gi·ªçng\\s*nam|gi·ªçng\\s*n·ªØ|nam|n·ªØ|ƒëk|ƒëi·ªáp\\s*kh√∫c)\\s*:\\s*',\n",
    "        '',\n",
    "        text,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # 4Ô∏è‚É£ X√≥a to√†n b·ªô n·ªôi dung trong ngo·∫∑c tr√≤n, ngo·∫∑c vu√¥ng n·∫øu c√≥\n",
    "    text = re.sub(r'[\\(\\[].*?[\\)\\]]', '', text)\n",
    "\n",
    "    # 5Ô∏è‚É£ Thay d·∫•u & b·∫±ng ch·ªØ \"v√†\"\n",
    "    text = text.replace('&', 'v√†')\n",
    "\n",
    "    # 6Ô∏è‚É£ Chuy·ªÉn to√†n b·ªô sang ch·ªØ th∆∞·ªùng\n",
    "    text = text.lower()\n",
    "\n",
    "    # 7Ô∏è‚É£ Gi·ªØ l·∫°i ch·ªØ c√°i, s·ªë, kho·∫£ng tr·∫Øng **v√† d·∫•u ph·∫©y**\n",
    "    text = re.sub(r'[^a-z√†√°·∫£√£·∫°ƒÉ·∫±·∫Ø·∫≥·∫µ·∫∑√¢·∫ß·∫•·∫©·∫´·∫≠√®√©·∫ª·∫Ω·∫π√™·ªÅ·∫ø·ªÉ·ªÖ·ªá'\n",
    "                  r'√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªì·ªë·ªï·ªó·ªô∆°·ªù·ªõ·ªü·ª°·ª£'\n",
    "                  r'√π√∫·ªß≈©·ª•∆∞·ª´·ª©·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµƒë0-9,\\s]', '', text)\n",
    "\n",
    "    # 8Ô∏è‚É£ Chu·∫©n h√≥a kho·∫£ng tr·∫Øng\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# === Ch·∫°y x·ª≠ l√Ω ===\n",
    "df = pd.read_csv('normalized_tkaraoke_standard_clean.csv')\n",
    "\n",
    "df['lyrics'] = df['lyrics'].astype(str).apply(clean_lyrics)\n",
    "\n",
    "# L∆∞u k·∫øt qu·∫£\n",
    "output_path = 'done_tkaraoke_nhacvn.csv'\n",
    "df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"‚úÖ ƒê√£ chu·∫©n h√≥a lyrics (bao g·ªìm x√≥a 'ƒêK:') & l∆∞u t·∫°i '{output_path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23756bb9d667a57",
   "metadata": {},
   "source": [
    "# Refill c·ªôt 'lyricists' , n·∫øu tr·ªëng th√¨ l·∫•y composers l·∫•p qua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc669acb6b774f68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T10:30:10.345267Z",
     "start_time": "2025-10-23T10:30:04.735512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë d√≤ng 'lyricists' b·ªã tr·ªëng ho·∫∑c thi·∫øu trong done_lyrics_nhacvn.csv: 78785\n",
      "S·ªë d√≤ng 'lyricists' c√≤n thi·∫øu sau khi ƒëi·ªÅn: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dm/b6833525473fb0p2gk_x1dmm0000gp/T/ipykernel_3041/1941505324.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['lyricists'] = df['lyricists'].replace(['', '[]', '[ ]', 'nan', np.nan], np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: refill_lyricists_nhacvn.csv\n",
      "S·ªë d√≤ng 'lyricists' b·ªã tr·ªëng ho·∫∑c thi·∫øu trong done_tkaraoke_nhacvn.csv: 46905\n",
      "S·ªë d√≤ng 'lyricists' c√≤n thi·∫øu sau khi ƒëi·ªÅn: 0\n",
      "‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: refill_lyricists_tkaraoke.csv\n"
     ]
    }
   ],
   "source": [
    "def fill_missing_lyricists(input_file_name, output_file_name):\n",
    "    # ƒê·ªçc file CSV\n",
    "    df = pd.read_csv(input_file_name)\n",
    "\n",
    "    # ƒê·∫øm tr∆∞·ªõc khi x·ª≠ l√Ω\n",
    "    missing_before = df['lyricists'].isna().sum() + (df['lyricists'].astype(str).str.strip().isin(['', '[]'])).sum()\n",
    "    print(f\"S·ªë d√≤ng 'lyricists' b·ªã tr·ªëng ho·∫∑c thi·∫øu trong {input_file_name}: {missing_before}\")\n",
    "\n",
    "    # Chu·∫©n h√≥a gi√° tr·ªã tr·ªëng th√†nh NaN\n",
    "    df['lyricists'] = df['lyricists'].replace(['', '[]', '[ ]', 'nan', np.nan], np.nan)\n",
    "\n",
    "    # ƒêi·ªÅn lyricists t·ª´ composers n·∫øu lyricists ƒëang NaN\n",
    "    df['lyricists'] = df['lyricists'].fillna(df['composers'])\n",
    "\n",
    "    # ƒê·∫øm l·∫°i sau khi x·ª≠ l√Ω\n",
    "    missing_after = df['lyricists'].isna().sum()\n",
    "    print(f\"S·ªë d√≤ng 'lyricists' c√≤n thi·∫øu sau khi ƒëi·ªÅn: {missing_after}\")\n",
    "\n",
    "    # L∆∞u ra file CSV m·ªõi\n",
    "    df.to_csv(output_file_name, index=False, encoding='utf-8-sig')\n",
    "    print(f\"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: {output_file_name}\")\n",
    "\n",
    "\n",
    "# === V√≠ d·ª• s·ª≠ d·ª•ng ===\n",
    "fill_missing_lyricists(\"done_lyrics_nhacvn.csv\", \"refill_lyricists_nhacvn.csv\")\n",
    "fill_missing_lyricists(\"done_tkaraoke_nhacvn.csv\", \"refill_lyricists_tkaraoke.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9984ecae278f07b9",
   "metadata": {},
   "source": [
    "# Fill c·ªôt source cho t·ª´ng trang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550819a9593daed0",
   "metadata": {},
   "source": [
    "## Th·ªëng k√™ nh·ªØng th·ªÉ lo·∫°i nh·∫°c n∆∞·ªõc ngo√†i NhacVN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72e217d2b73a0dac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:36:42.594207Z",
     "start_time": "2025-10-25T07:36:41.344165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C√°c d·∫°ng 'Nh·∫°c ...' t√¨m th·∫•y trong composers/lyricists:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern_found</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ngo·∫°i'</td>\n",
       "      <td>2534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ngo·∫°i (Trung Hoa)'</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ngo·∫°i</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ngo·∫°i (Trung Hoa)</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ngo·∫°i (Ph√°p)'</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Ngo·∫°i (Trung Hoa'</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Ngo·∫°i: Johnny Mandel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Ngo·∫°i (ƒêan M·∫°ch)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Ngo·∫°i (√Åo)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Ngo·∫°i (Argentina)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pattern_found  count\n",
       "0                 Ngo·∫°i'   2534\n",
       "1     Ngo·∫°i (Trung Hoa)'    776\n",
       "2                  Ngo·∫°i    488\n",
       "3      Ngo·∫°i (Trung Hoa)    150\n",
       "4          Ngo·∫°i (Ph√°p)'    136\n",
       "..                   ...    ...\n",
       "63     Ngo·∫°i (Trung Hoa'      1\n",
       "64  Ngo·∫°i: Johnny Mandel      1\n",
       "65      Ngo·∫°i (ƒêan M·∫°ch)      1\n",
       "66            Ngo·∫°i (√Åo)      1\n",
       "67     Ngo·∫°i (Argentina)      1\n",
       "\n",
       "[68 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === ƒê·ªçc d·ªØ li·ªáu ===\n",
    "df = pd.read_csv(\"filled_source_tkaraoke.csv\")\n",
    "\n",
    "# === G·ªôp composer v√† lyricists l·∫°i ƒë·ªÉ kh·∫£o s√°t d·ªÖ h∆°n ===\n",
    "combined = df['composers'].fillna('') + ' | ' + df['lyricists'].fillna('')\n",
    "\n",
    "# === T√¨m c√°c c·ª•m c√≥ d·∫°ng \"Nh·∫°c ...\", \"Nh·∫°c ... L·ªùi Vi·ªát\" ===\n",
    "pattern = r\"Ngo·∫°i[^,;\\]\\[]*\"\n",
    "matches = []\n",
    "\n",
    "for text in combined:\n",
    "    found = re.findall(pattern, str(text))\n",
    "    if found:\n",
    "        matches.extend(found)\n",
    "\n",
    "# === ƒê∆∞a v√†o DataFrame th·ªëng k√™ t·∫ßn su·∫•t xu·∫•t hi·ªán ===\n",
    "survey = pd.Series(matches).value_counts().reset_index()\n",
    "survey.columns = ['pattern_found', 'count']\n",
    "\n",
    "# === In ra k·∫øt qu·∫£ kh·∫£o s√°t ===\n",
    "print(\"C√°c d·∫°ng 'Nh·∫°c ...' t√¨m th·∫•y trong composers/lyricists:\")\n",
    "display(survey.head(100))  # hi·ªÉn th·ªã top 50 k·∫øt qu·∫£\n",
    "output = survey.to_csv(\"hello.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76185d6c8a8af399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:02:40.106054Z",
     "start_time": "2025-10-25T07:02:40.103384Z"
    }
   },
   "outputs": [],
   "source": [
    "#chu·∫©n h√≥a l·∫°i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53fb761115b57d78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:21:00.262182Z",
     "start_time": "2025-10-25T07:19:53.921609Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chu·∫©n h√≥a composers & lyricists: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78785/78785 [01:02<00:00, 1265.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ ghi file: l3/normalized_v3_no_unknown.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "# === ƒê·ªçc d·ªØ li·ªáu ===\n",
    "df = pd.read_csv(\"filled_source_nhacvn.csv\")\n",
    "\n",
    "# === Danh s√°ch c·ª•m t·ª´ c·∫ßn nh·∫≠n d·∫°ng ===\n",
    "music_keywords = [\n",
    "    \"Nh·∫°c Hoa L·ªùi Vi·ªát\", \"Nh·∫°c Ngo·∫°i L·ªùi Vi·ªát\", \"Nh·∫°c N∆∞·ªõc Ngo√†i\", \"Nh·∫°c Ph√°p L·ªùi Vi·ªát\",\n",
    "    \"Nh·∫°c Nh·∫≠t L·ªùi Vi·ªát\", \"Nh·∫°c H√†n L·ªùi Vi·ªát\", \"Nh·∫°c n∆∞·ªõc ngo√†i\", \"Nh·∫°c Nga L·ªùi Vi·ªát\",\n",
    "    \"Nh·∫°c Th√°i L·ªùi Vi·ªát\", \"Nh·∫°c Hong Kong\", \"Nh·∫°c Ph√°p\", \"Nh·∫°c H·∫£i Ngo·∫°i\",\n",
    "    \"Nh·∫°c Th√°i Lan L·ªùi Vi·ªát\", \"Nh·∫°c sƒ©)\", \"Nh·∫°c D√¢n Gian\", \"Nh·∫°c ngo·∫°i LV\",\n",
    "    \"Nh·∫°c Nga\", \"Nh·∫°c ngo·∫°i\", \"Nh·∫°c H√†n Qu·ªëc\", \"Nh·∫°c phim\", \"Nh·∫°c ƒê·∫°o\",\n",
    "    \"Nh·∫°c N∆∞·ªõc Ngo√†i L·ªùi Vi·ªát\", \"Nh·∫°c Nguy·ªÖn K·∫ø Khuy·∫øn\", \"Nh·∫°c √ù\", \"Nh·∫°c Trung Qu·ªëc\",\n",
    "    \"Nh·∫°c Ch√®o\", \"Nh·∫°c Anh\", \"Nh·∫°c H√†n\", \"Nh·∫°c Trong Phim\",\n",
    "]\n",
    "\n",
    "# === Danh s√°ch gi√° tr·ªã \"v√¥ nghƒ©a\" c·∫ßn x√≥a lu√¥n ===\n",
    "unknown_terms = {\"unknown\", \"Unknown\", \"Kh√¥ng r√µ\", \"?\", \"none\", \"None\", \"NaN\"}\n",
    "\n",
    "# === Chu·∫©n b·ªã c·ªôt genres (ƒë·∫£m b·∫£o l√† list) ===\n",
    "if \"genres\" not in df.columns:\n",
    "    df[\"genres\"] = [[] for _ in range(len(df))]\n",
    "else:\n",
    "    df[\"genres\"] = df[\"genres\"].apply(\n",
    "        lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith(\"[\") else ([] if pd.isna(x) else [x])\n",
    "    )\n",
    "\n",
    "# === H√†m chu·∫©n h√≥a t·ª´ng √¥ (d·∫°ng list ho·∫∑c chu·ªói) ===\n",
    "def normalize_field(value):\n",
    "    \"\"\"L√†m s·∫°ch gi√° tr·ªã c·ªßa composer/lyricist\"\"\"\n",
    "    found = []\n",
    "\n",
    "    # 1Ô∏è‚É£ N·∫øu l√† NaN ho·∫∑c None\n",
    "    if pd.isna(value):\n",
    "        return \"\", []\n",
    "\n",
    "    # 2Ô∏è‚É£ N·∫øu l√† list ƒë∆∞·ª£c l∆∞u d·∫°ng string\n",
    "    if isinstance(value, str) and value.startswith(\"[\"):\n",
    "        try:\n",
    "            value = ast.literal_eval(value)\n",
    "        except Exception:\n",
    "            value = [value]\n",
    "\n",
    "    # 3Ô∏è‚É£ N·∫øu l√† list th·∫≠t\n",
    "    if isinstance(value, list):\n",
    "        # B·ªè Unknown v√† c√°c m·ª•c v√¥ nghƒ©a\n",
    "        clean_items = []\n",
    "        for item in value:\n",
    "            if not isinstance(item, str):\n",
    "                continue\n",
    "            item = item.strip()\n",
    "            if item.lower() in [t.lower() for t in unknown_terms]:\n",
    "                continue  # b·ªè qua Unknown\n",
    "            # t√¨m c·ª•m \"Nh·∫°c ...\"\n",
    "            matched = [kw for kw in music_keywords if re.search(re.escape(kw), item, re.IGNORECASE)]\n",
    "            if matched:\n",
    "                found.extend(matched)\n",
    "            else:\n",
    "                clean_items.append(item)\n",
    "        new_value = \", \".join(clean_items)\n",
    "    else:\n",
    "        # 4Ô∏è‚É£ N·∫øu l√† chu·ªói ƒë∆°n\n",
    "        text = value.strip()\n",
    "        if text.lower() in [t.lower() for t in unknown_terms]:\n",
    "            return \"\", []\n",
    "        new_value = text\n",
    "        for kw in music_keywords:\n",
    "            if re.search(re.escape(kw), new_value, re.IGNORECASE):\n",
    "                found.append(kw)\n",
    "                new_value = re.sub(re.escape(kw), \"\", new_value, flags=re.IGNORECASE)\n",
    "\n",
    "        new_value = re.sub(r\"\\s*[,;|]+\\s*\", \", \", new_value.strip())\n",
    "        new_value = re.sub(r\"\\s{2,}\", \" \", new_value).strip(\" ,;|\")\n",
    "\n",
    "    return new_value.strip(), found\n",
    "\n",
    "# === √Åp d·ª•ng cho to√†n b·ªô d·ªØ li·ªáu ===\n",
    "for idx in tqdm(range(len(df)), desc=\"Chu·∫©n h√≥a composers & lyricists\"):\n",
    "    composer = df.at[idx, \"composers\"]\n",
    "    lyricist = df.at[idx, \"lyricists\"]\n",
    "\n",
    "    new_composer, genres1 = normalize_field(composer)\n",
    "    new_lyricist, genres2 = normalize_field(lyricist)\n",
    "\n",
    "    df.at[idx, \"composers\"] = new_composer\n",
    "    df.at[idx, \"lyricists\"] = new_lyricist\n",
    "    df.at[idx, \"genres\"] = sorted(set(df.at[idx, \"genres\"] + genres1 + genres2))\n",
    "\n",
    "# === Xu·∫•t file k·∫øt qu·∫£ ===\n",
    "output_file = \"l3/normalized_v3_no_unknown.csv\"\n",
    "df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"‚úÖ ƒê√£ ghi file: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0ea52bc1c10cf",
   "metadata": {},
   "source": [
    "# NHACVN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab1c68b8f9cef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# === ƒê·ªçc file ƒë·∫ßu v√†o ===\n",
    "input_file = \"refill_lyricists_nhacvn.csv\"  # üëà ƒë·ªïi t√™n n·∫øu c·∫ßn\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# === H√†m nh·∫≠n di·ªán qu·ªëc gia d·ª±a tr√™n composers + lyricists ===\n",
    "def detect_source(row):\n",
    "    text = str(row['composers']) + ' ' + str(row['lyricists'])\n",
    "    text = text.lower()\n",
    "\n",
    "    mapping = {\n",
    "        'hoa': 'Trung Qu·ªëc',\n",
    "        'trung qu·ªëc': 'Trung Qu·ªëc',\n",
    "        'hong kong': 'Trung Qu·ªëc',\n",
    "        'h√†n': 'H√†n Qu·ªëc',\n",
    "        'h√†n qu·ªëc': 'H√†n Qu·ªëc',\n",
    "        'nh·∫≠t': 'Nh·∫≠t B·∫£n',\n",
    "        'ph√°p': 'Ph√°p',\n",
    "        'nga': 'Nga',\n",
    "        'anh': 'Anh',\n",
    "        'm·ªπ': 'M·ªπ',\n",
    "        '√Ω': '√ù',\n",
    "        'th√°i': 'Th√°i Lan',\n",
    "        'th√°i lan': 'Th√°i Lan',\n",
    "        'n∆∞·ªõc ngo√†i': 'Nh·∫°c n∆∞·ªõc ngo√†i',\n",
    "        'ngo·∫°i': 'Nh·∫°c n∆∞·ªõc ngo√†i',\n",
    "        # 'h·∫£i ngo·∫°i' KH√îNG ƒë∆∞·ª£c t√≠nh l√† n∆∞·ªõc ngo√†i\n",
    "    }\n",
    "\n",
    "    # ∆Øu ti√™n lo·∫°i tr·ª´ \"nh·∫°c h·∫£i ngo·∫°i\" => Vi·ªát Nam\n",
    "    if re.search(r\"nh·∫°c\\s*h·∫£i\\s*ngo·∫°i\", text):\n",
    "        return \"Vi·ªát Nam\"\n",
    "\n",
    "    # D√≤ c√°c t·ª´ kh√≥a qu·ªëc gia kh√°c\n",
    "    for key, value in mapping.items():\n",
    "        if re.search(rf\"nh·∫°c\\s*{key}\", text):\n",
    "            return value\n",
    "\n",
    "    return 'Vi·ªát Nam'  # M·∫∑c ƒë·ªãnh n·∫øu kh√¥ng kh·ªõp\n",
    "\n",
    "# === √Åp d·ª•ng v√†o DataFrame ===\n",
    "df['source'] = df.apply(detect_source, axis=1)\n",
    "\n",
    "# === Xu·∫•t file k·∫øt qu·∫£ ===\n",
    "output_file = \"filled_source_nhacvn.csv\"\n",
    "df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"‚úÖ ƒê√£ t·∫°o file: {output_file} (Nh·∫°c H·∫£i Ngo·∫°i ƒë∆∞·ª£c t√≠nh l√† Vi·ªát Nam)\")\n",
    "\n",
    "# === Th·ªëng k√™ nhanh ===\n",
    "print(\"\\nüìä Th·ªëng k√™ gi√° tr·ªã trong c·ªôt 'source':\")\n",
    "print(df['source'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0841a9cf2410f45",
   "metadata": {},
   "source": [
    "# TKARAOKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b43d96ca890c7bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:31:48.896638Z",
     "start_time": "2025-10-25T07:31:47.384848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ kh·∫£o s√°t v√†o file: survey_source_tkaraoke.csv\n",
      "üìä C√°c d·∫°ng 'Ngo·∫°i' / 'Ngoai' t√¨m th·∫•y trong composers ho·∫∑c lyricists:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern_found</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ngo·∫°i L·ªùi Vi·ªát'</td>\n",
       "      <td>1710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ngo·∫°i)'</td>\n",
       "      <td>1292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ngo·∫°i'</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ngo·∫°i LV'</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ngo·∫°i'</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pattern_found  count\n",
       "0  Ngo·∫°i L·ªùi Vi·ªát'   1710\n",
       "1          Ngo·∫°i)'   1292\n",
       "2           Ngo·∫°i'     12\n",
       "3        ngo·∫°i LV'      8\n",
       "4           ngo·∫°i'      4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# === ƒê·ªçc d·ªØ li·ªáu ===\n",
    "df = pd.read_csv(\"filled_source_nhacvn.csv\")\n",
    "\n",
    "# === G·ªôp composer v√† lyricists l·∫°i ƒë·ªÉ kh·∫£o s√°t ===\n",
    "combined = df['composers'].fillna('') + ' | ' + df['lyricists'].fillna('')\n",
    "\n",
    "# === T√¨m t·∫•t c·∫£ c·ª•m c√≥ ch·ª©a ‚ÄúNgo·∫°i‚Äù ho·∫∑c ‚ÄúNgoai‚Äù ===\n",
    "pattern = r\"[Nn]go[a·∫°]i[^\\]\\|,;]*\"\n",
    "matches = []\n",
    "\n",
    "for text in combined:\n",
    "    found = re.findall(pattern, str(text))\n",
    "    if found:\n",
    "        matches.extend(found)\n",
    "\n",
    "# === Th·ªëng k√™ t·∫ßn su·∫•t xu·∫•t hi·ªán ===\n",
    "survey = pd.Series(matches).value_counts().reset_index()\n",
    "survey.columns = ['pattern_found', 'count']\n",
    "\n",
    "# === L∆∞u file kh·∫£o s√°t ===\n",
    "output_file = \"survey_source_tkaraoke.csv\"\n",
    "survey.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ kh·∫£o s√°t v√†o file: {output_file}\")\n",
    "print(\"üìä C√°c d·∫°ng 'Ngo·∫°i' / 'Ngoai' t√¨m th·∫•y trong composers ho·∫∑c lyricists:\")\n",
    "display(survey.head(69))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a660d31c1912ad72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T07:56:25.322235Z",
     "start_time": "2025-10-25T07:56:06.668571Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chu·∫©n h√≥a TKaraoke composers & lyricists: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49296/49296 [00:16<00:00, 3055.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ ghi file: l3/normalized_tkaraoke_no_unknown.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === ƒê·ªçc d·ªØ li·ªáu TKaraoke ===\n",
    "df = pd.read_csv(\"filled_source_tkaraoke.csv\")\n",
    "\n",
    "# === C√°c c·ª•m nh·∫≠n di·ªán \"Nh·∫°c Ngo·∫°i\" trong TKaraoke ===\n",
    "foreign_keywords = [\n",
    "    \"Ngo·∫°i\", \"Ngo·∫°i Qu·ªëc\", \"Ngo·∫°i.\", \"Ngo·∫°i '\", \"Ngo·∫°i '\", \"Ngo·∫°i -\",\n",
    "    \"Ngo·∫°i (Trung Hoa)\", \"Ngo·∫°i (Trung Qu·ªëc)\", \"Ngo·∫°i (Ph√°p)\", \"Ngo·∫°i (Anh)\",\n",
    "    \"Ngo·∫°i (Nga)\", \"Ngo·∫°i (H√†n Qu·ªëc)\", \"Ngo·∫°i (Nh·∫≠t)\", \"Ngo·∫°i (Th√°i Lan)\",\n",
    "    \"Ngo·∫°i (√ù)\", \"Ngo·∫°i (T√¢y Ban Nha)\", \"Ngo·∫°i (·∫§n ƒê·ªô)\", \"Ngo·∫°i (ƒê·ª©c)\",\n",
    "    \"Ngo·∫°i (ƒê√†i Loan)\", \"Ngo·∫°i (M·ªπ)\", \"Ngo·∫°i (Hoa)\", \"Ngo·∫°i (Columbia)\",\n",
    "    \"Ngo·∫°i (Tri·ªÅu Ti√™n)\", \"Ngo·∫°i (Indonexia)\", \"Ngo·∫°i (Malaysia)\",\n",
    "    \"Ngo·∫°i (Philipin)\", \"Ngo·∫°i (B·ªì ƒê√†o Nha)\", \"Ngo·∫°i (H√† Lan)\",\n",
    "    \"Ngo·∫°i (√Åo)\", \"Ngo·∫°i (ƒêan M·∫°ch)\", \"Ngo·∫°i (Argentina)\", \"Ngo·∫°i (Qu·ªëc)\",\n",
    "    \"Ngo·∫°i Phi Ti√™n\", \"Ngo·∫°i KimNguy·ªát Tr·∫ßn L√™ T√∫\", \"Ngo·∫°i (Antonio Vivaldi)\"\n",
    "]\n",
    "\n",
    "# === C√°c gi√° tr·ªã v√¥ nghƒ©a c·∫ßn x√≥a h·∫≥n ===\n",
    "unknown_terms = {\"unknown\", \"Unknown\", \"Kh√¥ng r√µ\", \"?\", \"none\", \"None\", \"NaN\",\"Ch∆∞a Bi·∫øt\", \"Ch∆∞ Bi·∫øt\"}\n",
    "\n",
    "# === ƒê·∫£m b·∫£o c·ªôt genres t·ªìn t·∫°i v√† l√† list ===\n",
    "if \"genres\" not in df.columns:\n",
    "    df[\"genres\"] = [[] for _ in range(len(df))]\n",
    "else:\n",
    "    df[\"genres\"] = df[\"genres\"].apply(\n",
    "        lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith(\"[\") else ([] if pd.isna(x) else [x])\n",
    "    )\n",
    "\n",
    "# === H√†m x·ª≠ l√Ω t·ª´ng √¥ ===\n",
    "def normalize_tkaraoke_field(value):\n",
    "    \"\"\"L√†m s·∫°ch composer/lyricist cho d·ªØ li·ªáu TKaraoke\"\"\"\n",
    "    found = []\n",
    "\n",
    "    if pd.isna(value):\n",
    "        return \"\", []\n",
    "\n",
    "    # N·∫øu l√† list l∆∞u d·∫°ng string\n",
    "    if isinstance(value, str) and value.startswith(\"[\"):\n",
    "        try:\n",
    "            value = ast.literal_eval(value)\n",
    "        except Exception:\n",
    "            value = [value]\n",
    "\n",
    "    # N·∫øu l√† list th·∫≠t\n",
    "    if isinstance(value, list):\n",
    "        clean_items = []\n",
    "        for item in value:\n",
    "            if not isinstance(item, str):\n",
    "                continue\n",
    "            item = item.strip()\n",
    "            if item.lower() in [t.lower() for t in unknown_terms]:\n",
    "                continue  # lo·∫°i Unknown\n",
    "            # nh·∫≠n di·ªán \"Ngo·∫°i...\"\n",
    "            matched = [kw for kw in foreign_keywords if re.search(re.escape(kw), item, re.IGNORECASE)]\n",
    "            if matched:\n",
    "                found.extend(matched)\n",
    "            else:\n",
    "                clean_items.append(item)\n",
    "        new_value = \", \".join(clean_items)\n",
    "    else:\n",
    "        # Chu·ªói th∆∞·ªùng\n",
    "        text = value.strip()\n",
    "        if text.lower() in [t.lower() for t in unknown_terms]:\n",
    "            return \"\", []\n",
    "        new_value = text\n",
    "        for kw in foreign_keywords:\n",
    "            if re.search(re.escape(kw), new_value, re.IGNORECASE):\n",
    "                found.append(kw)\n",
    "                new_value = re.sub(re.escape(kw), \"\", new_value, flags=re.IGNORECASE)\n",
    "\n",
    "        new_value = re.sub(r\"\\s*[,;|]+\\s*\", \", \", new_value.strip())\n",
    "        new_value = re.sub(r\"\\s{2,}\", \" \", new_value).strip(\" ,;|\")\n",
    "\n",
    "    return new_value.strip(), found\n",
    "\n",
    "# === √Åp d·ª•ng cho to√†n b·ªô d·ªØ li·ªáu ===\n",
    "for idx in tqdm(range(len(df)), desc=\"Chu·∫©n h√≥a TKaraoke composers & lyricists\"):\n",
    "    composer = df.at[idx, \"composers\"]\n",
    "    lyricist = df.at[idx, \"lyricists\"]\n",
    "\n",
    "    new_composer, genres1 = normalize_tkaraoke_field(composer)\n",
    "    new_lyricist, genres2 = normalize_tkaraoke_field(lyricist)\n",
    "\n",
    "    df.at[idx, \"composers\"] = new_composer\n",
    "    df.at[idx, \"lyricists\"] = new_lyricist\n",
    "    df.at[idx, \"genres\"] = sorted(set(df.at[idx, \"genres\"] + genres1 + genres2))\n",
    "\n",
    "# === Xu·∫•t file k·∫øt qu·∫£ ===\n",
    "output_file = \"l3/normalized_tkaraoke_no_unknown.csv\"\n",
    "df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"‚úÖ ƒê√£ ghi file: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3658c361b8ce742d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T11:44:56.845853Z",
     "start_time": "2025-10-24T11:44:53.241481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ t·∫°o file: filled_source_tkaraoke.csv\n",
      "\n",
      "üìä Th·ªëng k√™ gi√° tr·ªã c·ªôt 'source':\n",
      "source\n",
      "Vi·ªát Nam           46501\n",
      "Nh·∫°c n∆∞·ªõc ngo√†i     1881\n",
      "Trung Qu·ªëc           545\n",
      "Ph√°p                 139\n",
      "Anh                   71\n",
      "Nh·∫≠t B·∫£n              53\n",
      "H√†n Qu·ªëc              50\n",
      "Th√°i Lan              17\n",
      "T√¢y Ban Nha            6\n",
      "√ù                      6\n",
      "Th·ª•y ƒêi·ªÉn              4\n",
      "√Åo                     3\n",
      "·∫§n ƒê·ªô                  3\n",
      "Mexico                 2\n",
      "ƒê√†i Loan               2\n",
      "M·ªπ                     2\n",
      "ƒê·ª©c                    2\n",
      "Indonesia              2\n",
      "B·ªì ƒê√†o Nha             1\n",
      "Tri·ªÅu Ti√™n             1\n",
      "ƒêan M·∫°ch               1\n",
      "Argentina              1\n",
      "Colombia               1\n",
      "Cuba                   1\n",
      "Malaysia               1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# === ƒê·ªçc file ƒë·∫ßu v√†o ===\n",
    "input_file = \"refill_lyricists_tkaraoke.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# === H√†m nh·∫≠n di·ªán qu·ªëc gia ho·∫∑c v√πng theo n·ªôi dung composers + lyricists ===\n",
    "def detect_source(row):\n",
    "    text = str(row['composers']) + ' ' + str(row['lyricists'])\n",
    "    text = text.lower()\n",
    "\n",
    "    # B·∫£ng quy ƒë·ªïi c√°c n∆∞·ªõc v√† v√πng l√£nh th·ªï th∆∞·ªùng g·∫∑p\n",
    "    mapping = {\n",
    "        # ƒê√¥ng √Å\n",
    "        'trung hoa': 'Trung Qu·ªëc',\n",
    "        'trung qu·ªëc': 'Trung Qu·ªëc',\n",
    "        'trung': 'Trung Qu·ªëc',\n",
    "        'ƒë√†i loan': 'ƒê√†i Loan',\n",
    "        'hong kong': 'Trung Qu·ªëc',\n",
    "        'tri·ªÅu ti√™n': 'Tri·ªÅu Ti√™n',\n",
    "        'h√†n qu·ªëc': 'H√†n Qu·ªëc',\n",
    "        'h√†n': 'H√†n Qu·ªëc',\n",
    "        'nh·∫≠t': 'Nh·∫≠t B·∫£n',\n",
    "\n",
    "        # ƒê√¥ng Nam √Å\n",
    "        'th√°i lan': 'Th√°i Lan',\n",
    "        'indonesia': 'Indonesia',\n",
    "        'indonexia': 'Indonesia',\n",
    "        'malaysia': 'Malaysia',\n",
    "        'philippin': 'Philippines',\n",
    "\n",
    "        # T√¢y √Å, Nam √Å\n",
    "        '·∫•n ƒë·ªô': '·∫§n ƒê·ªô',\n",
    "\n",
    "        # Ch√¢u √Çu\n",
    "        'ph√°p': 'Ph√°p',\n",
    "        'anh': 'Anh',\n",
    "        'ƒë·ª©c': 'ƒê·ª©c',\n",
    "        't√¢y ban nha': 'T√¢y Ban Nha',\n",
    "        '√Ω': '√ù',\n",
    "        '√°o': '√Åo',\n",
    "        'b·ªì ƒë√†o nha': 'B·ªì ƒê√†o Nha',\n",
    "        'th·ª•y ƒëi·ªÉn': 'Th·ª•y ƒêi·ªÉn',\n",
    "        'ƒëan m·∫°ch': 'ƒêan M·∫°ch',\n",
    "\n",
    "        # Ch√¢u M·ªπ\n",
    "        'm·ªπ': 'M·ªπ',\n",
    "        'cu ba': 'Cuba',\n",
    "        'columbia': 'Colombia',\n",
    "        'argentina': 'Argentina',\n",
    "        'mexico': 'Mexico',\n",
    "\n",
    "        # Ngo·∫°i qu·ªëc n√≥i chung\n",
    "        'ngo·∫°i qu·ªëc': 'Nh·∫°c n∆∞·ªõc ngo√†i',\n",
    "    }\n",
    "\n",
    "    # === D√≤ c√°c t·ª´ kh√≥a trong n·ªôi dung ===\n",
    "    for key, value in mapping.items():\n",
    "        # Nh·∫≠n d·∫°ng c·∫£ c√°c d·∫°ng ‚ÄúNgo·∫°i (Ph√°p)‚Äù, ‚ÄúNgo·∫°i(Trung)‚Äù, ‚ÄúNgo·∫°i : Johnny Mandel‚Äù\n",
    "        if re.search(rf\"ngo[a·∫°]i[^a-zA-Z0-9]*{key}\", text):\n",
    "            return value\n",
    "\n",
    "    # === N·∫øu c√≥ ‚ÄúNgo·∫°i‚Äù nh∆∞ng kh√¥ng r√µ qu·ªëc gia n√†o ===\n",
    "    if re.search(r\"ngo[a·∫°]i\", text):\n",
    "        return \"Nh·∫°c n∆∞·ªõc ngo√†i\"\n",
    "\n",
    "    # === Ng∆∞·ª£c l·∫°i, m·∫∑c ƒë·ªãnh l√† Vi·ªát Nam ===\n",
    "    return \"Vi·ªát Nam\"\n",
    "\n",
    "\n",
    "# === √Åp d·ª•ng h√†m nh·∫≠n di·ªán ===\n",
    "df['source'] = df.apply(detect_source, axis=1)\n",
    "\n",
    "# === Xu·∫•t k·∫øt qu·∫£ ===\n",
    "output_file = \"filled_source_tkaraoke.csv\"\n",
    "df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"‚úÖ ƒê√£ t·∫°o file: {output_file}\")\n",
    "\n",
    "# === Th·ªëng k√™ nhanh ===\n",
    "print(\"\\nüìä Th·ªëng k√™ gi√° tr·ªã c·ªôt 'source':\")\n",
    "print(df['source'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb50ea3ef3e7c5aa",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33703587cc5f0c02",
   "metadata": {},
   "source": [
    "Quy tr√¨nh merge nh∆∞ sau:\n",
    "- ƒê·∫ßu ti√™n n·ªëi 2 file l·∫°i v·ªõi nhau\n",
    "- Filter trong c·ªôt 'lyrics', n·∫øu c√≥ d√≤ng n√†o tr√πng nhau , ch·ªçn gi·ªØ l·∫°i d√≤ng c√≥ nhi·ªÅu d·ªØ li·ªáu nh·∫•t(case 1:n·∫øu d·ªØ li·ªáu duplicate ho√†n to√†n, gi·ªØ l·∫°i d√≤ng ƒë·∫ßu ti√™n; case 2: n·∫øu c√≥ s·ªë d·ªØ li·ªáu b·∫±ng nhau, gi·ªØ l·∫°i nh·ªØng d√≤ng ƒë√≥)\n",
    "- c·ªôt genres: n·∫øu c√≥ d√≤ng n√†o tr√πng nhau, g√¥m danh s√°ch th·ªÉ lo·∫°i l·∫°i v·ªõi nhau, lo·∫°i b·ªè tr√πng l·∫∑p trong danh s√°ch\n",
    "- urls : l·∫•y t·∫•t c·∫£ url c·ªßa nh·ªØng d√≤ng b·ªã tr√πng\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfcf66fb63fdda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noi file va detect\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# H√†m normalize lyrics\n",
    "def normalize_lyrics(text):\n",
    "    \"\"\"Chu·∫©n h√≥a lyrics ƒë·ªÉ so s√°nh\"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return ''\n",
    "\n",
    "    text = str(text)\n",
    "    # 1. Lo·∫°i b·ªè kho·∫£ng tr·∫Øng ƒë·∫ßu/cu·ªëi\n",
    "    text = text.strip()\n",
    "    # 2. Chuy·ªÉn th√†nh ch·ªØ th∆∞·ªùng\n",
    "    text = text.lower()\n",
    "    # 3. Thay '&' ‚Üí 'v√†'\n",
    "    text = text.replace('&', 'v√†')\n",
    "    # 4. Chu·∫©n h√≥a nhi·ªÅu space ‚Üí 1 space\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    return text\n",
    "\n",
    "# ƒê·ªçc 2 files\n",
    "print(\"=\" * 80)\n",
    "print(\"ƒêANG ƒê·ªåC FILES...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df1 = pd.read_csv('filled_source_nhacvn.csv')\n",
    "df2 = pd.read_csv('filled_source_tkaraoke.csv')\n",
    "\n",
    "# Th√™m metadata\n",
    "df1['_source_file'] = 'nhacvn'\n",
    "df1['_original_index'] = df1.index\n",
    "df2['_source_file'] = 'tkaraoke'\n",
    "df2['_original_index'] = df2.index\n",
    "\n",
    "print(f\"‚úì File nhacvn: {len(df1)} d√≤ng\")\n",
    "print(f\"‚úì File tkaraoke: {len(df2)} d√≤ng\")\n",
    "print()\n",
    "\n",
    "# N·ªëi 2 files\n",
    "combined = pd.concat([df1, df2], ignore_index=True)\n",
    "print(f\"‚úì T·ªïng s·ªë d√≤ng sau khi n·ªëi: {len(combined)}\")\n",
    "print()\n",
    "\n",
    "# Th√™m c·ªôt normalized lyrics\n",
    "combined['_normalized_lyrics'] = combined['lyrics'].apply(normalize_lyrics)\n",
    "\n",
    "# Lo·∫°i b·ªè c√°c d√≤ng c√≥ lyrics r·ªóng\n",
    "combined_filtered = combined[combined['_normalized_lyrics'] != ''].copy()\n",
    "print(f\"‚úì S·ªë d√≤ng c√≥ lyrics: {len(combined_filtered)}\")\n",
    "print()\n",
    "\n",
    "# Group by normalized lyrics\n",
    "print(\"=\" * 80)\n",
    "print(\"ƒêANG DETECT DUPLICATES...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "grouped = combined_filtered.groupby('_normalized_lyrics')\n",
    "\n",
    "# L·ªçc c√°c groups c√≥ > 1 d√≤ng (duplicates)\n",
    "duplicate_groups = []\n",
    "for normalized_lyrics, group in grouped:\n",
    "    if len(group) > 1:\n",
    "        duplicate_groups.append({\n",
    "            'normalized_lyrics': normalized_lyrics,\n",
    "            'count': len(group),\n",
    "            'data': group.sort_values(['_source_file', '_original_index'])\n",
    "        })\n",
    "\n",
    "print(f\"\\nüîç T√¨m th·∫•y {len(duplicate_groups)} nh√≥m tr√πng l·∫∑p\")\n",
    "print(f\"üìä T·ªïng s·ªë d√≤ng b·ªã tr√πng: {sum(g['count'] for g in duplicate_groups)}\")\n",
    "print()\n",
    "\n",
    "# Hi·ªÉn th·ªã chi ti·∫øt t·ª´ng group\n",
    "if len(duplicate_groups) > 0:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"CHI TI·∫æT C√ÅC NH√ìM TR√ôNG L·∫∂P\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    for idx, group in enumerate(duplicate_groups, 1):\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"NH√ìM #{idx} - {group['count']} d√≤ng tr√πng l·∫∑p\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "\n",
    "        for row_idx, (_, row) in enumerate(group['data'].iterrows(), 1):\n",
    "            print(f\"\\n--- D√≤ng {row_idx} [{row['_source_file'].upper()}] ---\")\n",
    "            print(f\"Title: {row['title']}\")\n",
    "            print(f\"Composers: {row['composers']}\")\n",
    "            print(f\"Lyricists: {row['lyricists']}\")\n",
    "            print(f\"Year: {row['year']}\")\n",
    "            print(f\"Genres: {row['genres']}\")\n",
    "            print(f\"Source: {row['source']}\")\n",
    "            print(f\"URLs: {row['urls']}\")\n",
    "            print(f\"Note: {row['note']}\")\n",
    "            print(f\"Lyrics preview: {str(row['lyrics'])[:150]}...\")\n",
    "            print(f\"Original index in file: {row['_original_index']}\")\n",
    "\n",
    "        print(f\"\\n{'-' * 80}\")\n",
    "\n",
    "else:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"‚úÖ KH√îNG C√ì DUPLICATES!\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"T·∫•t c·∫£ lyrics ƒë·ªÅu unique.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"HO√ÄN T·∫§T!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09470bb178eabe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "def parse_list_field(field):\n",
    "    \"\"\"Parse list field t·ª´ string format\"\"\"\n",
    "    if pd.isna(field) or field == '' or field == '[]':\n",
    "        return []\n",
    "    try:\n",
    "        # N·∫øu ƒë√£ l√† list th√¨ return lu√¥n\n",
    "        if isinstance(field, list):\n",
    "            return field\n",
    "        # Parse string format ['item1', 'item2']\n",
    "        result = ast.literal_eval(field)\n",
    "        return result if isinstance(result, list) else [result]\n",
    "    except:\n",
    "        return [str(field)]\n",
    "\n",
    "def merge_list_fields(values):\n",
    "    \"\"\"G·ªôp nhi·ªÅu list l·∫°i, lo·∫°i tr√πng, gi·ªØ th·ª© t·ª±\"\"\"\n",
    "    all_items = []\n",
    "    for val in values:\n",
    "        items = parse_list_field(val)\n",
    "        for item in items:\n",
    "            if item and item not in all_items:\n",
    "                all_items.append(item)\n",
    "    return all_items\n",
    "\n",
    "def select_best_title(titles):\n",
    "    \"\"\"Ch·ªçn title d√†i nh·∫•t v√† ƒë·∫ßy ƒë·ªß nh·∫•t\"\"\"\n",
    "    valid_titles = [t for t in titles if pd.notna(t) and t != '']\n",
    "    if not valid_titles:\n",
    "        return ''\n",
    "    # Ch·ªçn title d√†i nh·∫•t\n",
    "    return max(valid_titles, key=len)\n",
    "\n",
    "def select_best_year(years):\n",
    "    \"\"\"Ch·ªçn year h·ª£p l·ªá ƒë·∫ßu ti√™n (non-null)\"\"\"\n",
    "    valid_years = [y for y in years if pd.notna(y) and y != '']\n",
    "    return valid_years[0] if valid_years else np.nan\n",
    "\n",
    "def merge_sources(sources):\n",
    "    \"\"\"G·ªôp sources, ∆∞u ti√™n c·ª• th·ªÉ h∆°n\"\"\"\n",
    "    valid_sources = [s for s in sources if pd.notna(s) and s != '']\n",
    "    if not valid_sources:\n",
    "        return ''\n",
    "    # Lo·∫°i tr√πng\n",
    "    unique_sources = []\n",
    "    for s in valid_sources:\n",
    "        if s not in unique_sources:\n",
    "            unique_sources.append(s)\n",
    "    # N·∫øu ch·ªâ c√≥ 1 lo·∫°i th√¨ return\n",
    "    if len(unique_sources) == 1:\n",
    "        return unique_sources[0]\n",
    "    # N·∫øu c√≥ nhi·ªÅu lo·∫°i kh√°c nhau th√¨ g·ªôp\n",
    "    return ' | '.join(unique_sources)\n",
    "\n",
    "def merge_notes(notes):\n",
    "    \"\"\"G·ªôp notes n·∫øu kh√°c nhau\"\"\"\n",
    "    valid_notes = [n for n in notes if pd.notna(n) and n != '']\n",
    "    if not valid_notes:\n",
    "        return ''\n",
    "    # Lo·∫°i tr√πng\n",
    "    unique_notes = []\n",
    "    for n in valid_notes:\n",
    "        if n not in unique_notes:\n",
    "            unique_notes.append(n)\n",
    "    return ' | '.join(unique_notes)\n",
    "\n",
    "def merge_group(group_df):\n",
    "    \"\"\"Merge m·ªôt nh√≥m duplicate th√†nh 1 d√≤ng\"\"\"\n",
    "\n",
    "    # Title: ch·ªçn d√†i nh·∫•t\n",
    "    merged_title = select_best_title(group_df['title'].tolist())\n",
    "\n",
    "    # Composers: g·ªôp t·∫•t c·∫£, lo·∫°i tr√πng\n",
    "    merged_composers = merge_list_fields(group_df['composers'].tolist())\n",
    "\n",
    "    # Lyricists: g·ªôp t·∫•t c·∫£, lo·∫°i tr√πng\n",
    "    merged_lyricists = merge_list_fields(group_df['lyricists'].tolist())\n",
    "\n",
    "    # Year: l·∫•y gi√° tr·ªã h·ª£p l·ªá ƒë·∫ßu ti√™n\n",
    "    merged_year = select_best_year(group_df['year'].tolist())\n",
    "\n",
    "    # Genres: g·ªôp t·∫•t c·∫£, lo·∫°i tr√πng\n",
    "    merged_genres = merge_list_fields(group_df['genres'].tolist())\n",
    "\n",
    "    # Lyrics: gi·ªØ nguy√™n (ƒë√£ gi·ªëng nhau r·ªìi)\n",
    "    merged_lyrics = group_df['lyrics'].iloc[0]\n",
    "\n",
    "    # URLs: g·ªôp t·∫•t c·∫£\n",
    "    merged_urls = merge_list_fields(group_df['urls'].tolist())\n",
    "\n",
    "    # Source: g·ªôp ho·∫∑c gi·ªØ c·ª• th·ªÉ h∆°n\n",
    "    merged_source = merge_sources(group_df['source'].tolist())\n",
    "\n",
    "    # Note: g·ªôp n·∫øu kh√°c nhau\n",
    "    merged_note = merge_notes(group_df['note'].tolist())\n",
    "\n",
    "    return pd.Series({\n",
    "        'title': merged_title,\n",
    "        'composers': merged_composers,\n",
    "        'lyricists': merged_lyricists,\n",
    "        'year': merged_year,\n",
    "        'genres': merged_genres,\n",
    "        'lyrics': merged_lyrics,\n",
    "        'urls': merged_urls,\n",
    "        'source': merged_source,\n",
    "        'note': merged_note\n",
    "    })\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"B·∫ÆT ƒê·∫¶U MERGE DUPLICATES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# L·∫•y data t·ª´ cell tr∆∞·ªõc (combined_filtered v√† grouped)\n",
    "# N·∫øu ch∆∞a c√≥ th√¨ ph·∫£i ch·∫°y l·∫°i cell 1\n",
    "\n",
    "# T·∫°o dataframe k·∫øt qu·∫£\n",
    "merged_rows = []\n",
    "unique_rows = []\n",
    "\n",
    "total_groups = 0\n",
    "total_duplicates = 0\n",
    "\n",
    "for normalized_lyrics, group in grouped:\n",
    "    if len(group) > 1:\n",
    "        # Duplicate group - merge\n",
    "        total_groups += 1\n",
    "        total_duplicates += len(group)\n",
    "        merged_row = merge_group(group)\n",
    "        merged_rows.append(merged_row)\n",
    "    else:\n",
    "        # Unique row - gi·ªØ nguy√™n\n",
    "        row = group.iloc[0]\n",
    "        unique_rows.append({\n",
    "            'title': row['title'],\n",
    "            'composers': parse_list_field(row['composers']),\n",
    "            'lyricists': parse_list_field(row['lyricists']),\n",
    "            'year': row['year'],\n",
    "            'genres': parse_list_field(row['genres']),\n",
    "            'lyrics': row['lyrics'],\n",
    "            'urls': parse_list_field(row['urls']),\n",
    "            'source': row['source'],\n",
    "            'note': row['note']\n",
    "        })\n",
    "\n",
    "print(f\"\\n‚úì ƒê√£ merge {total_groups} nh√≥m duplicate ({total_duplicates} d√≤ng)\")\n",
    "print(f\"‚úì Gi·ªØ nguy√™n {len(unique_rows)} d√≤ng unique\")\n",
    "\n",
    "# G·ªôp merged v√† unique\n",
    "result_df = pd.concat([\n",
    "    pd.DataFrame(merged_rows),\n",
    "    pd.DataFrame(unique_rows)\n",
    "], ignore_index=True)\n",
    "\n",
    "print(f\"\\n‚úì T·ªïng s·ªë d√≤ng sau merge: {len(result_df)}\")\n",
    "print(f\"‚úì Gi·∫£m ƒë∆∞·ª£c: {len(combined_filtered) - len(result_df)} d√≤ng\")\n",
    "\n",
    "# Format l·∫°i list fields th√†nh string ƒë·ªÉ l∆∞u CSV\n",
    "result_df['composers'] = result_df['composers'].apply(lambda x: str(x) if x else '[]')\n",
    "result_df['lyricists'] = result_df['lyricists'].apply(lambda x: str(x) if x else '[]')\n",
    "result_df['genres'] = result_df['genres'].apply(lambda x: str(x) if x else '[]')\n",
    "result_df['urls'] = result_df['urls'].apply(lambda x: str(x) if x else '[]')\n",
    "\n",
    "# S·∫Øp x·∫øp l·∫°i c·ªôt theo th·ª© t·ª± mong mu·ªën\n",
    "column_order = ['title', 'composers', 'lyricists', 'year', 'genres', 'lyrics', 'urls', 'source', 'note']\n",
    "result_df = result_df[column_order]\n",
    "\n",
    "# L∆∞u file\n",
    "output_file = 'merged_nhacvnAndTkaraoke_result.csv'\n",
    "result_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\n‚úì ƒê√£ l∆∞u file: {output_file}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Hi·ªÉn th·ªã m·∫´u k·∫øt qu·∫£ merge\n",
    "print(\"\\nM·∫™U K·∫æT QU·∫¢ MERGE:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# L·∫•y 1 v√≠ d·ª• t·ª´ group ƒë√£ merge\n",
    "sample_merged = pd.DataFrame(merged_rows).head(3)\n",
    "for idx, row in sample_merged.iterrows():\n",
    "    print(f\"\\nD√≤ng {idx + 1}:\")\n",
    "    print(f\"  Title: {row['title']}\")\n",
    "    print(f\"  Composers: {row['composers']}\")\n",
    "    print(f\"  Lyricists: {row['lyricists']}\")\n",
    "    print(f\"  Year: {row['year']}\")\n",
    "    print(f\"  Genres: {row['genres']}\")\n",
    "    print(f\"  URLs count: {len(row['urls'])}\")\n",
    "    print(f\"  Source: {row['source']}\")\n",
    "    print(f\"  Note: {row['note']}\")\n",
    "    print(f\"  Lyrics preview: {str(row['lyrics'])[:100]}...\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(\"\\n‚úÖ HO√ÄN T·∫§T MERGE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92e7f16c7a4c0ad",
   "metadata": {},
   "source": [
    "Fill year cho cho data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10798a517aff7dba",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-10-26T01:08:17.285563Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:03:29 | INFO     | === B·∫Øt ƒë·∫ßu ƒëi·ªÅn c·ªôt 'year' s·ª≠ d·ª•ng MusicBrainz + Wikipedia + iTunes ===\n",
      "18:03:31 | INFO     | ƒê√£ ƒë·ªçc 64983 h√†ng t·ª´ file: output/merged_yearFilled_final_2.csv\n",
      "18:03:31 | INFO     | C·∫ßn ƒëi·ªÅn 'year' cho 7099 b√†i h√°t\n",
      "18:03:31 | INFO     | üöÄ S·ª≠ d·ª•ng 10 threads ƒë·ªÉ tƒÉng t·ªëc...\n",
      "Filling year:   1%|‚ñè         | 99/7099 [00:48<48:20,  2.41it/s]  18:04:22 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 100/7099\n",
      "Filling year:   3%|‚ñé         | 197/7099 [01:25<08:18, 13.86it/s]  18:04:58 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 200/7099\n",
      "Filling year:   4%|‚ñç         | 286/7099 [01:35<15:03,  7.54it/s]18:05:15 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 300/7099\n",
      "Filling year:   6%|‚ñå         | 399/7099 [02:29<29:52,  3.74it/s]  18:06:03 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 400/7099\n",
      "Filling year:   7%|‚ñã         | 499/7099 [03:05<1:07:28,  1.63it/s]18:06:39 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 500/7099\n",
      "Filling year:   8%|‚ñä         | 599/7099 [03:49<34:51,  3.11it/s]  18:07:24 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 600/7099\n",
      "Filling year:  10%|‚ñâ         | 699/7099 [04:12<21:19,  5.00it/s]  18:07:47 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 700/7099\n",
      "Filling year:  11%|‚ñà‚ñè        | 799/7099 [04:40<32:09,  3.26it/s]  18:08:14 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 800/7099\n",
      "Filling year:  13%|‚ñà‚ñé        | 899/7099 [05:05<16:39,  6.20it/s]  18:08:39 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 900/7099\n",
      "Filling year:  14%|‚ñà‚ñç        | 998/7099 [05:33<21:13,  4.79it/s]18:09:07 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 1000/7099\n",
      "Filling year:  15%|‚ñà‚ñå        | 1099/7099 [05:47<07:11, 13.90it/s]18:09:21 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 1100/7099\n",
      "Filling year:  17%|‚ñà‚ñã        | 1199/7099 [06:13<43:50,  2.24it/s]18:09:47 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 1200/7099\n",
      "Filling year:  18%|‚ñà‚ñä        | 1297/7099 [06:36<22:14,  4.35it/s]  18:10:10 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 1300/7099\n",
      "Filling year:  20%|‚ñà‚ñâ        | 1399/7099 [07:02<17:33,  5.41it/s]18:10:36 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 1400/7099\n",
      "Filling year:  21%|‚ñà‚ñà        | 1499/7099 [07:28<30:19,  3.08it/s]  18:11:02 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 1500/7099\n",
      "Filling year:  23%|‚ñà‚ñà‚ñé       | 1598/7099 [07:51<10:14,  8.94it/s]18:11:26 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 1600/7099\n",
      "Filling year:  24%|‚ñà‚ñà‚ñç       | 1699/7099 [08:26<22:43,  3.96it/s]  18:11:59 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 1700/7099\n",
      "Filling year:  25%|‚ñà‚ñà‚ñå       | 1799/7099 [08:54<28:33,  3.09it/s]18:12:28 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 1800/7099\n",
      "Filling year:  27%|‚ñà‚ñà‚ñã       | 1899/7099 [09:21<21:05,  4.11it/s]  18:12:54 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 1900/7099\n",
      "Filling year:  28%|‚ñà‚ñà‚ñä       | 1998/7099 [09:45<14:24,  5.90it/s]18:13:20 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 2000/7099\n",
      "Filling year:  30%|‚ñà‚ñà‚ñâ       | 2099/7099 [10:08<19:48,  4.21it/s]18:13:42 | INFO     | üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng 2100/7099\n",
      "Filling year:  30%|‚ñà‚ñà‚ñâ       | 2112/7099 [10:12<24:07,  3.45it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from functools import lru_cache\n",
    "import threading\n",
    "\n",
    "# ==================== LOGGING CONFIG ====================\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)-8s | %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "start_time = datetime.now()\n",
    "logger.info(\"=== B·∫Øt ƒë·∫ßu ƒëi·ªÅn c·ªôt 'year' s·ª≠ d·ª•ng MusicBrainz + Wikipedia + iTunes ===\")\n",
    "\n",
    "# ==================== FILE I/O ====================\n",
    "input_file = \"output/merged_yearFilled_final_2.csv\"\n",
    "output_file = \"output/merged_yearFilled_final_3.csv\"\n",
    "checkpoint_file = \"output/checkpoint_years.csv\"\n",
    "\n",
    "# Thread-safe lock cho vi·ªác ghi file\n",
    "file_lock = threading.Lock()\n",
    "\n",
    "# ==================== ƒê·ªåC D·ªÆ LI·ªÜU & CHECKPOINT ====================\n",
    "def load_data():\n",
    "    \"\"\"ƒê·ªçc d·ªØ li·ªáu t·ª´ checkpoint ho·∫∑c file g·ªëc\"\"\"\n",
    "    # Ki·ªÉm tra checkpoint tr∆∞·ªõc\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        logger.info(f\"üîÑ T√¨m th·∫•y checkpoint! ƒêang ƒë·ªçc t·ª´: {checkpoint_file}\")\n",
    "        df = pd.read_csv(checkpoint_file, encoding=\"utf-8-sig\")\n",
    "        df.columns = df.columns.str.strip().str.lower()\n",
    "        logger.info(f\"‚úÖ ƒê√£ t·∫£i checkpoint v·ªõi {len(df)} h√†ng\")\n",
    "        return df, True\n",
    "\n",
    "    # N·∫øu kh√¥ng c√≥ checkpoint, ƒë·ªçc file g·ªëc\n",
    "    try:\n",
    "        df = pd.read_csv(input_file, encoding=\"utf-8-sig\")\n",
    "        df.columns = df.columns.str.strip().str.lower()\n",
    "        logger.info(f\"ƒê√£ ƒë·ªçc {len(df)} h√†ng t·ª´ file: {input_file}\")\n",
    "        return df, False\n",
    "    except Exception as e:\n",
    "        logger.error(f\"L·ªói khi ƒë·ªçc file CSV: {e}\")\n",
    "        raise SystemExit(e)\n",
    "\n",
    "df, from_checkpoint = load_data()\n",
    "\n",
    "# ƒê·∫£m b·∫£o c√°c c·ªôt c·∫ßn thi·∫øt t·ªìn t·∫°i\n",
    "for col in [\"year\", \"note\"]:\n",
    "    if col not in df.columns:\n",
    "        df[col] = \"\"\n",
    "df[\"note\"] = df[\"note\"].astype(str)\n",
    "\n",
    "# ==================== H√ÄM 1: MusicBrainz ====================\n",
    "@lru_cache(maxsize=1000)\n",
    "def get_song_year_musicbrainz(title, artist=None):\n",
    "    try:\n",
    "        query = title\n",
    "        if artist:\n",
    "            query += f\" AND artist:{artist}\"\n",
    "\n",
    "        url = f\"https://musicbrainz.org/ws/2/recording/?query={query}&fmt=json&limit=1\"\n",
    "        headers = {\"User-Agent\": \"NhacVN-YearFiller/1.0 (example@gmail.com)\"}\n",
    "        r = requests.get(url, headers=headers, timeout=10)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "\n",
    "        recordings = data.get(\"recordings\", [])\n",
    "        if not recordings:\n",
    "            return None\n",
    "\n",
    "        rec = recordings[0]\n",
    "        releases = rec.get(\"releases\", [])\n",
    "        if not releases:\n",
    "            return None\n",
    "\n",
    "        date = releases[0].get(\"date\", \"\")\n",
    "        if not date:\n",
    "            return None\n",
    "\n",
    "        match = re.search(r\"\\b(19|20)\\d{2}\\b\", date)\n",
    "        if match:\n",
    "            return int(match.group(0))\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        # Ch·ªâ log error quan tr·ªçng\n",
    "        if \"timeout\" in str(e).lower():\n",
    "            logger.debug(f\"[MusicBrainz] Timeout: {title}\")\n",
    "        return None\n",
    "\n",
    "# ==================== H√ÄM 2: Wikipedia ====================\n",
    "@lru_cache(maxsize=1000)\n",
    "def get_song_year_wikipedia(title):\n",
    "    try:\n",
    "        headers = {\n",
    "            \"User-Agent\": \"NhacVN-YearFiller/1.0 (https://github.com/duynguyen or contact@example.com)\"\n",
    "        }\n",
    "\n",
    "        base_urls = [\n",
    "            \"https://vi.wikipedia.org/w/api.php\",\n",
    "            \"https://en.wikipedia.org/w/api.php\",\n",
    "        ]\n",
    "\n",
    "        for base_url in base_urls:\n",
    "            params = {\n",
    "                \"action\": \"query\",\n",
    "                \"list\": \"search\",\n",
    "                \"srsearch\": title,\n",
    "                \"format\": \"json\",\n",
    "                \"utf8\": 1,\n",
    "                \"srlimit\": 1,\n",
    "            }\n",
    "            r = requests.get(base_url, params=params, headers=headers, timeout=10)\n",
    "            if r.status_code == 403:\n",
    "                continue\n",
    "\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            search_results = data.get(\"query\", {}).get(\"search\", [])\n",
    "            if not search_results:\n",
    "                continue\n",
    "\n",
    "            page_title = search_results[0][\"title\"]\n",
    "            extract_url = f\"{base_url.replace('/w/api.php', '')}/api/rest_v1/page/summary/{page_title}\"\n",
    "            r = requests.get(extract_url, headers=headers, timeout=10)\n",
    "            if r.status_code == 403:\n",
    "                continue\n",
    "            r.raise_for_status()\n",
    "            summary_data = r.json()\n",
    "            extract = summary_data.get(\"extract\", \"\")\n",
    "\n",
    "            match = re.search(r\"\\b(19|20)\\d{2}\\b\", extract)\n",
    "            if match:\n",
    "                return int(match.group(0))\n",
    "\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"[Wikipedia] Error: {title}\")\n",
    "        return None\n",
    "\n",
    "# ==================== H√ÄM 3: iTunes (FIX L·ªñI 404) ====================\n",
    "@lru_cache(maxsize=1000)\n",
    "def get_song_year_itunes(title, artist=None):\n",
    "    try:\n",
    "        query = title\n",
    "        if artist:\n",
    "            query += f\" {artist}\"\n",
    "        url = \"https://itunes.apple.com/search\"\n",
    "        params = {\"term\": query, \"entity\": \"song\", \"limit\": 1, \"country\": \"us\"}\n",
    "        r = requests.get(url, params=params, timeout=10)\n",
    "\n",
    "        # FIX: Kh√¥ng raise error cho 404, ch·ªâ return None\n",
    "        if r.status_code == 404:\n",
    "            return None\n",
    "\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "\n",
    "        results = data.get(\"results\", [])\n",
    "        if not results:\n",
    "            return None\n",
    "\n",
    "        release_date = results[0].get(\"releaseDate\", \"\")\n",
    "        if not release_date:\n",
    "            return None\n",
    "\n",
    "        match = re.search(r\"\\b(19|20)\\d{2}\\b\", release_date)\n",
    "        if match:\n",
    "            return int(match.group(0))\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Ch·ªâ log l·ªói nghi√™m tr·ªçng, b·ªè qua 404\n",
    "        if \"404\" not in str(e):\n",
    "            logger.debug(f\"[iTunes] Error: {title}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# ==================== H√ÄM X·ª¨ L√ù 1 D√íNG ====================\n",
    "def process_single_row(idx, title, artist):\n",
    "    \"\"\"X·ª≠ l√Ω 1 b√†i h√°t v√† tr·∫£ v·ªÅ k·∫øt qu·∫£\"\"\"\n",
    "    # ∆Øu ti√™n 1: MusicBrainz\n",
    "    year = get_song_year_musicbrainz(title, artist)\n",
    "    source = \"MusicBrainz\"\n",
    "\n",
    "    # ∆Øu ti√™n 2: Wikipedia\n",
    "    if not year:\n",
    "        time.sleep(0.2)\n",
    "        year = get_song_year_wikipedia(title)\n",
    "        source = \"Wikipedia\" if year else None\n",
    "\n",
    "    # ∆Øu ti√™n 3: iTunes\n",
    "    if not year:\n",
    "        time.sleep(0.2)\n",
    "        year = get_song_year_itunes(title, artist)\n",
    "        source = \"iTunes\" if year else None\n",
    "\n",
    "    # Tr·∫£ v·ªÅ k·∫øt qu·∫£\n",
    "    if year:\n",
    "        return idx, year, f\"ƒë√£ fill 'year' s·ª≠ d·ª•ng {source}\"\n",
    "    else:\n",
    "        return idx, None, \"kh√¥ng t√¨m th·∫•y th√¥ng tin nƒÉm ph√°t h√†nh\"\n",
    "\n",
    "# ==================== QUY TR√åNH FILL D·ªÆ LI·ªÜU (ƒêA LU·ªíNG) ====================\n",
    "need_fill = df[\"year\"].isna() | (df[\"year\"].astype(str).str.strip() == \"\")\n",
    "indices = df[need_fill].index.tolist()\n",
    "logger.info(f\"C·∫ßn ƒëi·ªÅn 'year' cho {len(indices)} b√†i h√°t\")\n",
    "\n",
    "if len(indices) == 0:\n",
    "    logger.info(\"‚úÖ T·∫•t c·∫£ d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c ƒëi·ªÅn ƒë·∫ßy ƒë·ªß!\")\n",
    "else:\n",
    "    # C·∫•u h√¨nh ƒëa lu·ªìng (tƒÉng s·ªë workers ƒë·ªÉ ch·∫°y nhanh h∆°n)\n",
    "    MAX_WORKERS = 10  # C√≥ th·ªÉ tƒÉng l√™n 15-20 n·∫øu m·∫°ng ·ªïn ƒë·ªãnh\n",
    "    checkpoint_interval = 100  # L∆∞u checkpoint m·ªói 100 d√≤ng\n",
    "\n",
    "    logger.info(f\"üöÄ S·ª≠ d·ª•ng {MAX_WORKERS} threads ƒë·ªÉ tƒÉng t·ªëc...\")\n",
    "\n",
    "    processed_count = 0\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        # T·∫°o danh s√°ch tasks\n",
    "        futures = {}\n",
    "        for idx in indices:\n",
    "            title = df.loc[idx, \"title\"]\n",
    "            artist = None\n",
    "            if \"composers\" in df.columns and isinstance(df.loc[idx, \"composers\"], str):\n",
    "                artist = df.loc[idx, \"composers\"].split(\",\")[0]\n",
    "\n",
    "            future = executor.submit(process_single_row, idx, title, artist)\n",
    "            futures[future] = idx\n",
    "\n",
    "        # X·ª≠ l√Ω k·∫øt qu·∫£ v·ªõi progress bar\n",
    "        for future in tqdm(as_completed(futures), total=len(indices), desc=\"Filling year\"):\n",
    "            idx, year, note = future.result()\n",
    "\n",
    "            # C·∫≠p nh·∫≠t DataFrame\n",
    "            if year:\n",
    "                df.loc[idx, \"year\"] = year\n",
    "            df.loc[idx, \"note\"] = note\n",
    "\n",
    "            processed_count += 1\n",
    "\n",
    "            # L∆∞u checkpoint ƒë·ªãnh k·ª≥ (thread-safe)\n",
    "            if processed_count % checkpoint_interval == 0:\n",
    "                with file_lock:\n",
    "                    df.to_csv(checkpoint_file, index=False, encoding=\"utf-8-sig\")\n",
    "                    logger.info(f\"üíæ ƒê√£ l∆∞u checkpoint t·∫°i d√≤ng {processed_count}/{len(indices)}\")\n",
    "\n",
    "# ==================== GHI FILE CU·ªêI ====================\n",
    "df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "logger.info(f\"‚úÖ ƒê√£ ghi file k·∫øt qu·∫£: {output_file}\")\n",
    "\n",
    "if os.path.exists(checkpoint_file):\n",
    "    os.remove(checkpoint_file)\n",
    "    logger.info(\"üóëÔ∏è ƒê√£ x√≥a checkpoint file\")\n",
    "\n",
    "elapsed = datetime.now() - start_time\n",
    "logger.info(f\"‚è±Ô∏è Th·ªùi gian ch·∫°y: {elapsed}\")\n",
    "logger.info(\"=== Ho√†n t·∫•t ƒëi·ªÅn c·ªôt 'year' (MusicBrainz + Wikipedia + iTunes) ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

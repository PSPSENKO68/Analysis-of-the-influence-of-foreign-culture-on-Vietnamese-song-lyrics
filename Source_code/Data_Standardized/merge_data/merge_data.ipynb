{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvzJ40jn4b2j",
        "outputId": "1677ff0b-6dee-41ec-a5c9-f438a1f108e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.14.1-cp312-cp312-macosx_10_13_x86_64.whl.metadata (12 kB)\n",
            "Downloading rapidfuzz-3.14.1-cp312-cp312-macosx_10_13_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m581.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-3.14.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install rapidfuzz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbunLbTPqHis"
      },
      "source": [
        "# L√†m s·∫°ch t·ª´ng data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "QX6Qmbd5tpEa",
        "outputId": "a2e1fec7-9176-43ec-a183-f754dc6f2e68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ L√†m s·∫°ch xong N05_timbaihat_final.csv (13764 d√≤ng)\n",
            "üéµ T·ªïng th·ªÉ lo·∫°i ƒë∆∞·ª£c th√™m t·ª´ composer/lyricist: 1742\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 13764,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11952,\n        \"samples\": [\n          \"c\\u00f3 nh\\u01b0 kh\\u00f4ng c\\u00f3\",\n          \"n\\u1ed7i nh\\u1edb m\\u01b0a phai\",\n          \"ch\\u1eb3ng th\\u1ec3 b\\u1eb1ng ng\\u01b0\\u1eddi ta\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"composers\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lyricists\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 1970,\n        \"max\": 2025,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          2025,\n          2009,\n          2015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genres\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lyrics\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13265,\n        \"samples\": [\n          \"Khi em \\u00f4m anh trong tay n\\u00f3i v\\u1edbi anh r\\u1eb1ng: \\u201cM\\u00ecnh l\\u00e0 b\\u1ea1n b\\u00e8 v\\u1eabn t\\u1ed1t h\\u01a1n l\\u00e0 nh\\u00e2n t\\u00ecnh.\\u201d L\\u1eddi n\\u00e0y ch\\u1ec9 t\\u1eeb ph\\u00eda em, c\\u00f3 bao gi\\u1edd em t\\u1ef1 h\\u1ecfi: \\u201cLi\\u1ec7u r\\u1eb1ng \\u0111i\\u1ec1u n\\u00e0y c\\u00f3 khi\\u1ebfn tim anh qu\\u1eb7n \\u0111au?\\u201d Anh kh\\u00f4ng bu\\u00f4ng tay c\\u0169ng ch\\u1eb3ng n\\u00edu gi\\u1eef em l\\u1ea1i V\\u00ec m\\u00ecnh m\\u00e0 c\\u00e0ng c\\u1ed1 g\\u1eafng s\\u1ebd c\\u00e0ng \\u0111au l\\u00f2ng Th\\u00e0 m\\u00ecnh t\\u1ef1 ch\\u1ecbu t\\u1ed5n th\\u01b0\\u01a1ng \\u0111\\u1ec3 em ra \\u0111i \\u0111\\u01b0\\u1ee3c vui C\\u1ea7n g\\u00ec ch\\u1ea7n ch\\u1edd \\u0111\\u1ec3 bi\\u1ebft ai ng\\u01b0\\u1eddi \\u0111\\u00fang sai... Th\\u00e0 anh im ti\\u1ebfng, c\\u1ed1 g\\u1eafng nh\\u1eabn ch\\u1ecbu kh\\u00f4ng mu\\u1ed1n ch\\u00fang ta c\\u0103ng th\\u1eb3ng h\\u01a1n Khi hai ti\\u1ebfng \\u00e1i t\\u00ecnh ch\\u1eb3ng nh\\u01b0 l\\u00fac \\u0111\\u1ea7u Th\\u00e0 chia tay \\u0111\\u1ec3 mai sau l\\u1ee1 g\\u1eb7p l\\u1ea1i v\\u1eabn c\\u00f3 th\\u1ec3 n\\u1edf n\\u1ee5 c\\u01b0\\u1eddi v\\u1eabn c\\u00f2n h\\u01a1n n\\u00edu k\\u00e9o th\\u01b0\\u01a1ng \\u0111au. M\\u1ed9t m\\u00ecnh anh v\\u1eabn s\\u1ed1ng t\\u1ed1t, v\\u1eabn lu\\u00f4n m\\u1ec9m c\\u01b0\\u1eddi, d\\u1eabu ch\\u01b0a ph\\u1ea3i l\\u00fac n\\u00e0y Nh\\u01b0ng anh bi\\u1ebft ch\\u1ec9 m\\u00ecnh t\\u1ef1 th\\u00e2n ch\\u1eefa l\\u00e0nh D\\u00f9 anh kh\\u00f4ng mu\\u1ed1n nh\\u01b0ng ph\\u1ea3i c\\u1ed1 h\\u1ecdc \\u0111\\u01b0\\u1ee3c c\\u00e1ch th\\u01b0\\u01a1ng l\\u1ea5y b\\u1ea3n th\\u00e2n Bi\\u1ebfn ni\\u1ec1m \\u0111au th\\u00e0nh n\\u1ed7i vui cho ng\\u00e0y sau\",\n          \"Tr\\u1eddi xanh m\\u00e2y m\\u00f9 gi\\u0103ng, l\\u00f2ng \\u0111au tim qu\\u1ea1nh v\\u1eafng Nh\\u1edb d\\u00e1ng ai b\\u00ean h\\u1ed3 s\\u01b0\\u01a1ng tr\\u1eafng T\\u00ecnh duy\\u00ean ta c\\u00f2n \\u0111\\u00e2y m\\u00e0 nay khu\\u1ea5t xa ng\\u00e0n m\\u00e2y Trong men say ai bu\\u00f4ng n\\u1ed7i s\\u1ea7u Hoa kia r\\u01a1i h\\u1eefu t\\u00ecnh, m\\u00e0 ta c\\u1edb sao v\\u00f4 h\\u00ecnh Y\\u00eau th\\u01b0\\u01a1ng theo gi\\u00f3 m\\u00e2y m\\u1ea5t r\\u1ed3i Chinh chi\\u1ebfn kia l\\u00e2u d\\u00e0i, l\\u00f2ng \\u0111au con tim th\\u1eaft l\\u1ea1i Nh\\u1edb ti\\u1ebfng ai b\\u00ean th\\u1ec1m ng\\u01b0\\u1eddi h\\u1ee1i B\\u00f3ng tr\\u0103ng \\u0111\\u00e3 phai t\\u00e0n r\\u1ed3i, b\\u00ean h\\u1ed3 nguy\\u1ec7t c\\u00f2n phai ph\\u00f4i b\\u00f3ng \\u0111\\u00f4i l\\u1ee9a \\u0111ang h\\u1eb9n th\\u1ec1 mong ki\\u1ebfp sau l\\u00e0m phu th\\u00ea Ai \\u0111\\u00e3 khi\\u1ebfn tr\\u0103ng t\\u00e0n, ai mang tim d\\u1edf dang \\u00d4m \\u0111\\u1ed1ng tro t\\u00e0n, n\\u00e0ng kh\\u00f3c than, ki\\u1ebfp b\\u1ebd b\\u00e0ng Interlude: Ph\\u1eadn h\\u1ed3ng nhan em nh\\u01b0 tr\\u0103ng kia d\\u1ea7n t\\u00e0n \\u0110\\u1eddi c\\u00f4 li\\u00eau ai \\u0111\\u00e2u th\\u01b0\\u01a1ng thay ph\\u1ea7n n\\u00e0ng Nh\\u00ecn ng\\u01b0\\u1eddi \\u0111i sang s\\u00f4ng M\\u00e0 \\u0111au \\u0111\\u1ebfn v\\u1ee1 tan l\\u00f2ng Cu\\u1ed1i chi\\u1ec1u ho\\u00e0ng h\\u00f4n in b\\u00f3ng ai Ng\\u1ed3i \\u0111au \\u0111\\u1edbn v\\u1edbi ti\\u1ebfng th\\u1edf d\\u00e0i Kh\\u00f3c cho ng\\u01b0\\u1eddi, kh\\u00f3c cho ta hay kh\\u00f3c cho ai A2: Hoa kia r\\u01a1i h\\u1eefu t\\u00ecnh, m\\u00e0 ta c\\u1edb sao v\\u00f4 h\\u00ecnh Y\\u00eau th\\u01b0\\u01a1ng theo gi\\u00f3 m\\u00e2y m\\u1ea5t r\\u1ed3i Chinh chi\\u1ebfn kia l\\u00e2u d\\u00e0i, l\\u00f2ng \\u0111au tim sao th\\u1eaft l\\u1ea1i Nh\\u1edb d\\u00e1ng ai b\\u00ean th\\u1ec1m ng\\u01b0\\u1eddi h\\u1ee1i B\\u00f3ng tr\\u0103ng \\u0111\\u00e3 phai t\\u00e0n r\\u1ed3i, b\\u00ean h\\u1ed3 nguy\\u1ec7t c\\u00f2n phai ph\\u00f4i b\\u00f3ng \\u0111\\u00f4i l\\u1ee9a \\u0111ang h\\u1eb9n th\\u1ec1 mong ki\\u1ebfp sau l\\u00e0m phu th\\u00ea Ai n\\u1ee1 khi\\u1ebfn tr\\u0103ng t\\u00e0n, ai mang tim d\\u1edf dang \\u00d4m \\u0111\\u1ed1ng tro t\\u00e0n, n\\u00e0ng kh\\u00f3c than, ki\\u1ebfp b\\u1ebd b\\u00e0ng Ng\\u01b0\\u1eddi s\\u1ea7u, ng\\u01b0\\u1eddi nh\\u1edb, ng\\u01b0\\u1eddi mong. Ng\\u01b0\\u1eddi \\u0111\\u1ee3i, ng\\u01b0\\u1eddi ng\\u00f3ng ng\\u01b0\\u1eddi tr\\u00f4ng Mong c\\u00f3 b\\u00f3ng thuy\\u1ec1n v\\u1ec1 tim ta \\u0111\\u1eadu b\\u1ebfn. L\\u00f2ng n\\u00e0y c\\u00e0ng nh\\u1edb kh\\u00f4ng phai, ng\\u01b0\\u1eddi \\u0111\\u1ee3i ng\\u01b0\\u1eddi ch\\u1eb3ng th\\u01b0\\u01a1ng ai Duy\\u00ean ki\\u1ebfp kh\\u00f4ng th\\u00e0nh h\\u1eb9n ki\\u1ebfp sau, ng\\u01b0\\u1eddi h\\u1ee1i\",\n          \"C\\u1ea7u nguy\\u1ec7n em y\\u00eau n\\u01a1i nao Lu\\u00f4n \\u0111\\u01b0\\u1ee3c h\\u1ea1nh ph\\u00fac D\\u1eabu nh\\u00e2n gian c\\u00f2n \\u0111\\u00e2y Bao nhi\\u00eau lo toan cu\\u1ed9c \\u0111\\u1eddi M\\u1ed9t th\\u1eddi v\\u00f4 t\\u00e2m v\\u00f4 t\\u01b0 Anh kh\\u00f4ng suy ngh\\u0129 \\u0110\\u00e2u ch\\u1ecbu l\\u1eafng nghe Nh\\u1eefng g\\u00ec em n\\u00f3i nh\\u1eefng g\\u00ec em khuy\\u00ean M\\u1ed9t ng\\u01b0\\u1eddi hy sinh cho anh Qua bao n\\u0103m th\\u00e1ng \\u0110\\u00e1nh m\\u1ea5t \\u0111i m\\u1ed9t th\\u1eddi thanh xu\\u00e2n T\\u00f3c em th\\u00eam s\\u1ee3i b\\u1ea1c Cu\\u1ed9c \\u0111\\u1eddi anh bao long \\u0111ong Nh\\u01b0 con s\\u00f3ng v\\u1ed7 S\\u00f3ng lang thang ngo\\u00e0i kh\\u01a1i Bi\\u1ebft n\\u01a1i nao s\\u1ebd d\\u1eebng ch\\u00e2n S\\u1ebd \\u0111i \\u0111\\u00e2u v\\u1ec1 \\u0111\\u00e2u \\u0111\\u1ec3 t\\u00ecm l\\u1ea1i H\\u00ecnh b\\u00f3ng \\u0111\\u00e3 m\\u1ea5t \\u0111i t\\u1eeb b\\u1ea5y l\\u00e2u L\\u1ea1c m\\u1ea5t nhau trong v\\u00f2ng tay Anh m\\u1edbi th\\u1ea5y N\\u01a1i em m\\u00e3i m\\u00e3i l\\u00e0 b\\u00ecnh y\\u00ean Mu\\u1ed1n dang \\u0111\\u00f4i v\\u00f2ng tay v\\u00ec gi\\u1edd n\\u00e0y C\\u1ea3m gi\\u00e1c tr\\u1ed1ng v\\u1eafng thi\\u1ebfu \\u0111i l\\u00e0n h\\u01a1i \\u1ea5m Anh mu\\u1ed1n bay \\u0111i th\\u1eadt xa th\\u1eadt xa N\\u01a1i em m\\u00e3i m\\u00e3i l\\u00e0 b\\u00ecnh y\\u00ean M\\u1ed9t ng\\u01b0\\u1eddi hy sinh cho anh Qua bao n\\u0103m th\\u00e1ng \\u0110\\u00e1nh m\\u1ea5t \\u0111i m\\u1ed9t th\\u1eddi thanh xu\\u00e2n T\\u00f3c em th\\u00eam s\\u1ee3i b\\u1ea1c Cu\\u1ed9c \\u0111\\u1eddi anh bao long \\u0111ong Nh\\u01b0 con s\\u00f3ng v\\u1ed7 S\\u00f3ng lang thang ngo\\u00e0i kh\\u01a1i Bi\\u1ebft n\\u01a1i nao s\\u1ebd d\\u1eebng ch\\u00e2n S\\u1ebd \\u0111i \\u0111\\u00e2u v\\u1ec1 \\u0111\\u00e2u \\u0111\\u1ec3 t\\u00ecm l\\u1ea1i H\\u00ecnh b\\u00f3ng \\u0111\\u00e3 m\\u1ea5t \\u0111i t\\u1eeb b\\u1ea5y l\\u00e2u L\\u1ea1c m\\u1ea5t nhau trong v\\u00f2ng tay Anh m\\u1edbi th\\u1ea5y N\\u01a1i em m\\u00e3i m\\u00e3i l\\u00e0 b\\u00ecnh y\\u00ean Mu\\u1ed1n dang \\u0111\\u00f4i v\\u00f2ng tay v\\u00ec gi\\u1edd n\\u00e0y C\\u1ea3m gi\\u00e1c tr\\u1ed1ng v\\u1eafng thi\\u1ebfu \\u0111i l\\u00e0n h\\u01a1i \\u1ea5m Anh mu\\u1ed1n bay \\u0111i th\\u1eadt xa th\\u1eadt xa N\\u01a1i em m\\u00e3i m\\u00e3i l\\u00e0 b\\u00ecnh y\\u00ean S\\u1ebd \\u0111i \\u0111\\u00e2u v\\u1ec1 \\u0111\\u00e2u \\u0111\\u1ec3 t\\u00ecm l\\u1ea1i H\\u00ecnh b\\u00f3ng \\u0111\\u00e3 m\\u1ea5t \\u0111i t\\u1eeb b\\u1ea5y l\\u00e2u L\\u1ea1c m\\u1ea5t nhau trong v\\u00f2ng tay Anh m\\u1edbi th\\u1ea5y N\\u01a1i em m\\u00e3i m\\u00e3i l\\u00e0 b\\u00ecnh y\\u00ean Mu\\u1ed1n dang \\u0111\\u00f4i v\\u00f2ng tay v\\u00ec gi\\u1edd n\\u00e0y C\\u1ea3m gi\\u00e1c tr\\u1ed1ng v\\u1eafng thi\\u1ebfu \\u0111i l\\u00e0n h\\u01a1i \\u1ea5m Anh mu\\u1ed1n bay \\u0111i th\\u1eadt xa th\\u1eadt xa N\\u01a1i em m\\u00e3i m\\u00e3i l\\u00e0 b\\u00ecnh y\\u00ean Anh mu\\u1ed1n bay \\u0111i th\\u1eadt xa th\\u1eadt xa N\\u01a1i em m\\u00e3i m\\u00e3i l\\u00e0 b\\u00ecnh y\\u00ean N\\u01a1i em m\\u00e3i m\\u00e3i l\\u00e0 b\\u00ecnh y\\u00ean\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"urls\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Vi\\u1ec7t Nam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"note\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-bc5fa43a-8384-48f8-8376-273f1a3b0ea0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>composers</th>\n",
              "      <th>lyricists</th>\n",
              "      <th>year</th>\n",
              "      <th>genres</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>urls</th>\n",
              "      <th>source</th>\n",
              "      <th>note</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>anh kh√¥ng ph·∫£i l√† ch√∫ r·ªÉ</td>\n",
              "      <td>[San Ji]</td>\n",
              "      <td>[San Ji]</td>\n",
              "      <td>2025</td>\n",
              "      <td>[V-Pop]</td>\n",
              "      <td>Em gi·ªù ƒë√£ c√≥ ng∆∞·ªùi kh√°c C√≤n anh lang thang tro...</td>\n",
              "      <td>[https://timbaihat.com/loi-bai-hat-anh-khong-p...</td>\n",
              "      <td>Vi·ªát Nam</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ƒëi m·ªôt ƒë∆∞·ªùng v·ªÅ hai h∆∞·ªõng ost cha t√¥i ng∆∞·ªùi ·ªü l·∫°i</td>\n",
              "      <td>[Ph√πng Ti·∫øn Minh]</td>\n",
              "      <td>[Ph√πng Ti·∫øn Minh]</td>\n",
              "      <td>2025</td>\n",
              "      <td>[Phim, V-Pop]</td>\n",
              "      <td>Hoa phi√™u phi√™u C√¢y xi√™u xi√™u Theo ch√¢n ai v·ªÅ ...</td>\n",
              "      <td>[https://timbaihat.com/loi-bai-hat-di-mot-duon...</td>\n",
              "      <td>Vi·ªát Nam</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>em</td>\n",
              "      <td>[DTAP, INUS]</td>\n",
              "      <td>[DTAP, INUS]</td>\n",
              "      <td>2025</td>\n",
              "      <td>[V-Pop]</td>\n",
              "      <td>Ng·∫Øm nh√¨n em l·∫∑ng ng·ªìi Trong √°nh d∆∞∆°ng t√†n C√¢u...</td>\n",
              "      <td>[https://timbaihat.com/loi-bai-hat-em-dong-nhi...</td>\n",
              "      <td>Vi·ªát Nam</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>t√¨nh y√™u b·∫•t di·ªát remix</td>\n",
              "      <td>[DK L√¢m]</td>\n",
              "      <td>[DK L√¢m]</td>\n",
              "      <td>2025</td>\n",
              "      <td>[Dance Vi·ªát]</td>\n",
              "      <td>H√†ng ng√†n ng∆∞·ªùi trong nh√¢n gian Nh∆∞ng ta ch·ªâ s...</td>\n",
              "      <td>[https://timbaihat.com/loi-bai-hat-tinh-yeu-ba...</td>\n",
              "      <td>Vi·ªát Nam</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>kh√≥ chi·ªÅu</td>\n",
              "      <td>[DTAP]</td>\n",
              "      <td>[DTAP]</td>\n",
              "      <td>2025</td>\n",
              "      <td>[V-Pop]</td>\n",
              "      <td>ƒê·ª´ng n√≥i t√¥i th·∫≠t ki√™u Khi m√† ta ch∆∞a h·ªÅ quen ...</td>\n",
              "      <td>[https://timbaihat.com/loi-bai-hat-kho-chieu-d...</td>\n",
              "      <td>Vi·ªát Nam</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc5fa43a-8384-48f8-8376-273f1a3b0ea0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc5fa43a-8384-48f8-8376-273f1a3b0ea0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc5fa43a-8384-48f8-8376-273f1a3b0ea0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-eda6fdf5-3e28-4b81-be71-ff94c82f0631\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eda6fdf5-3e28-4b81-be71-ff94c82f0631')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-eda6fdf5-3e28-4b81-be71-ff94c82f0631 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               title          composers  \\\n",
              "0                           anh kh√¥ng ph·∫£i l√† ch√∫ r·ªÉ           [San Ji]   \n",
              "1  ƒëi m·ªôt ƒë∆∞·ªùng v·ªÅ hai h∆∞·ªõng ost cha t√¥i ng∆∞·ªùi ·ªü l·∫°i  [Ph√πng Ti·∫øn Minh]   \n",
              "2                                                 em       [DTAP, INUS]   \n",
              "3                            t√¨nh y√™u b·∫•t di·ªát remix           [DK L√¢m]   \n",
              "4                                          kh√≥ chi·ªÅu             [DTAP]   \n",
              "\n",
              "           lyricists  year         genres  \\\n",
              "0           [San Ji]  2025        [V-Pop]   \n",
              "1  [Ph√πng Ti·∫øn Minh]  2025  [Phim, V-Pop]   \n",
              "2       [DTAP, INUS]  2025        [V-Pop]   \n",
              "3           [DK L√¢m]  2025   [Dance Vi·ªát]   \n",
              "4             [DTAP]  2025        [V-Pop]   \n",
              "\n",
              "                                              lyrics  \\\n",
              "0  Em gi·ªù ƒë√£ c√≥ ng∆∞·ªùi kh√°c C√≤n anh lang thang tro...   \n",
              "1  Hoa phi√™u phi√™u C√¢y xi√™u xi√™u Theo ch√¢n ai v·ªÅ ...   \n",
              "2  Ng·∫Øm nh√¨n em l·∫∑ng ng·ªìi Trong √°nh d∆∞∆°ng t√†n C√¢u...   \n",
              "3  H√†ng ng√†n ng∆∞·ªùi trong nh√¢n gian Nh∆∞ng ta ch·ªâ s...   \n",
              "4  ƒê·ª´ng n√≥i t√¥i th·∫≠t ki√™u Khi m√† ta ch∆∞a h·ªÅ quen ...   \n",
              "\n",
              "                                                urls    source  note  \n",
              "0  [https://timbaihat.com/loi-bai-hat-anh-khong-p...  Vi·ªát Nam   NaN  \n",
              "1  [https://timbaihat.com/loi-bai-hat-di-mot-duon...  Vi·ªát Nam   NaN  \n",
              "2  [https://timbaihat.com/loi-bai-hat-em-dong-nhi...  Vi·ªát Nam   NaN  \n",
              "3  [https://timbaihat.com/loi-bai-hat-tinh-yeu-ba...  Vi·ªát Nam   NaN  \n",
              "4  [https://timbaihat.com/loi-bai-hat-kho-chieu-d...  Vi·ªát Nam   NaN  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "import string\n",
        "import ast\n",
        "\n",
        "# ==== C√ÅC H√ÄM C∆† B·∫¢N ====\n",
        "\n",
        "def clean_title(title: str) -> str:\n",
        "    if pd.isna(title): return ''\n",
        "    title = str(title).lower().strip().replace('&', 'v√†')\n",
        "    title = title.translate(str.maketrans('', '', string.punctuation.replace('&', '').replace(\"'\", '')))\n",
        "    return re.sub(r'\\s+', ' ', title).strip()\n",
        "\n",
        "def clean_lyrics(lyrics: str) -> str:\n",
        "    if pd.isna(lyrics) or not lyrics: return ''\n",
        "    lyrics = str(lyrics).strip()\n",
        "    lyrics = re.sub(r'\\s+', ' ', lyrics)\n",
        "    return lyrics[:5000]\n",
        "\n",
        "# ==== CHU·∫®N H√ìA & L√ÄM S·∫†CH GENRE ====\n",
        "\n",
        "def clean_genre(genre: str) -> str:\n",
        "    if not isinstance(genre, str): return ''\n",
        "    genre = genre.strip()\n",
        "    genre = re.sub(r'[\\(\\)\\.]', '', genre)\n",
        "    genre = re.sub(r'nh·∫°c|nhac', '', genre, flags=re.IGNORECASE)\n",
        "    genre = re.sub(r'\\s+', ' ', genre).strip()\n",
        "    return genre\n",
        "\n",
        "def _strip_accents_for_key(s: str) -> str:\n",
        "    if not isinstance(s, str): return ''\n",
        "    s = s.strip().lower()\n",
        "    s = unicodedata.normalize('NFKD', s)\n",
        "    s = ''.join(ch for ch in s if not unicodedata.combining(ch))\n",
        "    s = re.sub(r'[-‚Äì_]', ' ', s)\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    return s\n",
        "\n",
        "def normalize_genre(genre: str) -> str:\n",
        "    if not isinstance(genre, str) or not genre.strip(): return ''\n",
        "    orig_clean = clean_genre(genre)\n",
        "    key = _strip_accents_for_key(orig_clean)\n",
        "    mapping = {\n",
        "        'tre': 'Tr·∫ª', 'tru tinh': 'Tr·ªØ T√¨nh', 'trinh': 'Tr·ªãnh', 'vpop': 'V-Pop',\n",
        "        'viet remix': 'Vi·ªát Remix', 'que huong': 'Qu√™ H∆∞∆°ng', 'dan ca': 'D√¢n Ca',\n",
        "        'dan gian': 'D√¢n Ca', 'nuoc ngoai': 'N∆∞·ªõc Ngo√†i', 'ngoai': 'N∆∞·ªõc Ngo√†i',\n",
        "        'ngoai han quoc': 'Ngo·∫°i H√†n Qu·ªëc', 'ngoai my': 'Ngo·∫°i M·ªπ',\n",
        "        'ngoai trung hoa': 'Ngo·∫°i Trung Hoa', 'ngoai phap': 'Ngo·∫°i Ph√°p',\n",
        "        'ngoai nhat': 'Ngo·∫°i Nh·∫≠t', 'ngoai nga': 'Ngo·∫°i Nga', 'ngoai duc': 'Ngo·∫°i ƒê·ª©c',\n",
        "        'ngoai thai lan': 'Ngo·∫°i Th√°i Lan', 'ngoai loi viet': 'Ngo·∫°i L·ªùi Vi·ªát',\n",
        "        'hoa loi viet': 'Hoa L·ªùi Vi·ªát', 'phap loi viet': 'Ph√°p L·ªùi Vi·ªát',\n",
        "        'nhat loi viet': 'Nh·∫≠t L·ªùi Vi·ªát', 'han loi viet': 'H√†n L·ªùi Vi·ªát',\n",
        "        'dan ca loi viet': 'D√¢n Ca L·ªùi Vi·ªát', 'cach mang': 'C√°ch M·∫°ng',\n",
        "        'phat giao': 'Ph·∫≠t Gi√°o', 'edm viet': 'EDM Vi·ªát', 'rb viet': 'R&B Vi·ªát',\n",
        "        'rock viet': 'Rock Vi·ªát', 'vang': 'V√†ng', 'beat': 'Beat',\n",
        "        'thieu nhi': 'Thi·∫øu Nhi', 'khong loi': 'Kh√¥ng L·ªùi', 'hoa tau': 'H√≤a T·∫•u',\n",
        "        'thanh ca': 'T√¥n Gi√°o', 'cai luong': 'C·∫£i L∆∞∆°ng', 'phim': 'Phim',\n",
        "        'tet': 'Xu√¢n', 'giang sinh': 'Gi√°ng Sinh', 'chill': 'Chill', 'khac': 'Kh√°c'\n",
        "    }\n",
        "    if key in mapping: return mapping[key]\n",
        "    for k, v in mapping.items():\n",
        "        if k in key: return v\n",
        "    return re.sub(r'\\s+', ' ', orig_clean).strip().title()\n",
        "\n",
        "# ==== CLEAN COMPOSER / LYRICIST (C√ì CHUY·ªÇN GENRE) ====\n",
        "\n",
        "def clean_person_list(persons):\n",
        "    \"\"\"\n",
        "    L√†m s·∫°ch t√™n v√† chuy·ªÉn 'Nh·∫°c ... L·ªùi Vi·ªát' sang genres.\n",
        "    Tr·∫£ v·ªÅ tuple: (danh_s√°ch_ng∆∞·ªùi_d·ªçn_s·∫°ch, genres_chuy·ªÉn_t·ª´_person)\n",
        "    \"\"\"\n",
        "    if not isinstance(persons, list):\n",
        "        return [], []\n",
        "    cleaned, transferred_genres = [], []\n",
        "    trash_terms = [\"nhi·ªÅu nh·∫°c sƒ©\", \"nhi·ªÅu ngh·ªá sƒ©\", \"nhi·ªÅu ca sƒ©\", \"various artists\", \"nhi·ªÅu t√°c gi·∫£\", \"t√°c gi·∫£\"]\n",
        "\n",
        "    for p in persons:\n",
        "        if not isinstance(p, str): continue\n",
        "        p = re.sub(r\"[^a-zA-Z√Ä-·ªπ\\s\\-\\(\\)\\.]\", \"\", p.strip())\n",
        "        p = re.sub(r'\\s+', ' ', p).strip()\n",
        "        if not p: continue\n",
        "\n",
        "        # N·∫øu ch·ª©a ‚ÄúNh·∫°c ... L·ªùi Vi·ªát‚Äù => chuy·ªÉn sang genre\n",
        "        if re.search(r\"nh·∫°c\\s*[\\w\\s√†-·ªπ]*\\s*l·ªùi\\s*vi·ªát\", p, flags=re.IGNORECASE):\n",
        "            transferred_genres.append(p.strip())\n",
        "            continue\n",
        "        if p.lower() in trash_terms: continue\n",
        "\n",
        "        cleaned.append(p)\n",
        "\n",
        "    return cleaned, transferred_genres\n",
        "\n",
        "# ==== X·ª¨ L√ù FILE CSV ====\n",
        "\n",
        "def parse_list_str(x):\n",
        "    if pd.isna(x): return []\n",
        "    if isinstance(x, list): return x\n",
        "    try:\n",
        "        val = ast.literal_eval(x)\n",
        "        if isinstance(val, list): return val\n",
        "    except Exception:\n",
        "        pass\n",
        "    x = x.strip().strip(\"[]\")\n",
        "    if not x: return []\n",
        "    return [i.strip().strip(\"'\\\"\") for i in re.split(r'\\s*,\\s*', x) if i.strip()]\n",
        "\n",
        "def clean_csv_input(path):\n",
        "    df = pd.read_csv(path)\n",
        "    for c in ['composers', 'lyricists', 'genres', 'urls']:\n",
        "        if c in df.columns:\n",
        "            df[c] = df[c].apply(parse_list_str)\n",
        "\n",
        "    # Chuy·ªÉn 'Nh·∫°c ... L·ªùi Vi·ªát' sang genre\n",
        "    transferred_genres = [[] for _ in range(len(df))]\n",
        "    for col in ['composers', 'lyricists']:\n",
        "        if col not in df.columns:\n",
        "            continue\n",
        "        new_col = []\n",
        "        for i, persons in enumerate(df[col]):\n",
        "            cleaned, extra_genres = clean_person_list(persons)\n",
        "            new_col.append(cleaned)\n",
        "            transferred_genres[i].extend(extra_genres)\n",
        "        df[col] = new_col\n",
        "\n",
        "    # Chu·∫©n h√≥a genres\n",
        "    total_added_genres = 0\n",
        "    if 'genres' in df.columns:\n",
        "        new_genres = []\n",
        "        for i, g in enumerate(df['genres']):\n",
        "            merged = g + transferred_genres[i]\n",
        "            normalized = [normalize_genre(x) for x in merged if x]\n",
        "            unique_norm = list(dict.fromkeys(normalized))\n",
        "            total_added_genres += len(transferred_genres[i])\n",
        "            new_genres.append(unique_norm)\n",
        "        df['genres'] = new_genres\n",
        "\n",
        "    # L√†m s·∫°ch c√°c tr∆∞·ªùng ch√≠nh\n",
        "    df['title'] = df['title'].apply(lambda x: clean_title(x))\n",
        "    if 'lyrics' in df.columns:\n",
        "        df['lyrics'] = df['lyrics'].apply(lambda x: clean_lyrics(x))\n",
        "\n",
        "    # === Ghi ƒë√® file g·ªëc ===\n",
        "    df.to_csv(path, index=False)\n",
        "\n",
        "    print(f\"‚úÖ L√†m s·∫°ch xong {path} ({len(df)} d√≤ng)\")\n",
        "    print(f\"üéµ T·ªïng th·ªÉ lo·∫°i ƒë∆∞·ª£c th√™m t·ª´ composer/lyricist: {total_added_genres}\")\n",
        "    return df\n",
        "\n",
        "# ==== DEMO D√ôNG ====\n",
        "df = clean_csv_input('N05_timbaihat_final.csv')\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UoUEhAbqM_L"
      },
      "source": [
        "# Merge c√°ch 1 (ƒëi·ªÅu ki·ªán title tr√πng + √≠t nh·∫•t 1 composer tr√πng)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvNhCxRv4ebO",
        "outputId": "d3e22470-ab21-4ea7-f6d5-9dfe985e7f30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìò ƒê·ªçc N01_hopamviet_final.csv (10422 d√≤ng)\n",
            "\n",
            "üöÄ B·∫Øt ƒë·∫ßu merge v·ªõi N01_hopamviet_final.csv\n",
            "\n",
            "üîÑ G·ªôp file 2/6: N02_timbaihat_final.csv\n",
            "üìò ƒê·ªçc N02_timbaihat_final.csv (18503 d√≤ng)\n",
            "\n",
            "üß© DEBUG MERGE #1: '60 nƒÉm cu·ªôc ƒë·ªùi'\n",
            "  composers=['Y V√¢n'] | lyricists=['Y V√¢n', 'Miu L√™'] | year=2015\n",
            "  genres=['Tr·ªØ T√¨nh', 'Tr·∫ª', 'V-Pop'] | urls=['https://hopamviet.vn/chord/song/60-nam-cuoc-doi/W8IUII6C.html', 'https://timbaihat.com/loi-bai-hat-60-nam-cuoc-doi-miu-le.html']\n",
            "\n",
            "üß© DEBUG MERGE #2: '7 love'\n",
            "  composers=['Nguy·ªÖn ƒê√¨nh V≈©'] | lyricists=['Nguy·ªÖn ƒê√¨nh V≈©'] | year=2021\n",
            "  genres=['Tr·∫ª', 'V-Pop'] | urls=['https://hopamviet.vn/chord/song/7-love/W8IU7UZ8.html', 'https://timbaihat.com/loi-bai-hat-7-love-nguyen-dinh-vu.html']\n",
            "\n",
            "üß© DEBUG MERGE #3: 'ai cho t√¥i t√¨nh y√™u'\n",
            "  composers=['Tr√∫c Ph∆∞∆°ng'] | lyricists=['Tr√∫c Ph∆∞∆°ng', 'B·∫£o H√¢n Bolero'] | year=2019\n",
            "  genres=['V√†ng', 'Tr·ªØ T√¨nh'] | urls=['https://hopamviet.vn/chord/song/ai-cho-toi-tinh-yeu/W8IU0FWO.html', 'https://timbaihat.com/loi-bai-hat-ai-cho-toi-tinh-yeu-bao-han-bolero.html']\n",
            "‚úÖ ƒê√£ merge 2309, th√™m 16194 d√≤ng m·ªõi.\n",
            "\n",
            "üîÑ G·ªôp file 3/6: N03_loibaihat_final.csv\n",
            "üìò ƒê·ªçc N03_loibaihat_final.csv (22897 d√≤ng)\n",
            "‚úÖ ƒê√£ merge 1050, th√™m 21847 d√≤ng m·ªõi.\n",
            "\n",
            "üîÑ G·ªôp file 4/6: N04_nhacvn_final.csv\n",
            "üìò ƒê·ªçc N04_nhacvn_final.csv (77444 d√≤ng)\n",
            "‚úÖ ƒê√£ merge 31170, th√™m 46274 d√≤ng m·ªõi.\n",
            "\n",
            "üîÑ G·ªôp file 5/6: N04_tkaraoke_final.csv\n",
            "üìò ƒê·ªçc N04_tkaraoke_final.csv (46430 d√≤ng)\n",
            "‚úÖ ƒê√£ merge 12013, th√™m 34417 d√≤ng m·ªõi.\n",
            "\n",
            "üîÑ G·ªôp file 6/6: N05_timbaihat_final.csv\n",
            "üìò ƒê·ªçc N05_timbaihat_final.csv (13764 d√≤ng)\n",
            "‚úÖ ƒê√£ merge 12951, th√™m 813 d√≤ng m·ªõi.\n",
            "üíæ L∆∞u: merged_final.csv\n",
            "\n",
            "üìä T·ªîNG K·∫æT:\n",
            "   T·ªïng s·ªë b√†i merge: 59493\n",
            "   T·ªïng s·ªë b√†i sau merge: 129967\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "# ==== H√ÄM H·ªñ TR·ª¢ ====\n",
        "\n",
        "def parse_list_str(x):\n",
        "    \"\"\"Chuy·ªÉn chu·ªói d·∫°ng ['A', 'B'] th√†nh list ['A', 'B'].\"\"\"\n",
        "    if pd.isna(x) or not isinstance(x, str):\n",
        "        return []\n",
        "    x = x.strip()\n",
        "    if x.startswith('[') and x.endswith(']'):\n",
        "        x = x[1:-1]\n",
        "    if not x.strip():\n",
        "        return []\n",
        "    items = [i.strip().strip(\"'\\\"\") for i in x.split(',') if i.strip()]\n",
        "    return items\n",
        "\n",
        "def get_comp_key(composers):\n",
        "    \"\"\"Tr·∫£ v·ªÅ frozenset ƒë·ªÉ so s√°nh nhanh danh s√°ch composer.\"\"\"\n",
        "    if not composers:\n",
        "        return frozenset()\n",
        "    try:\n",
        "        return frozenset([c.strip().lower() for c in composers if isinstance(c, str)])\n",
        "    except Exception:\n",
        "        return frozenset()\n",
        "\n",
        "def merge_unique_case_insensitive(a, b):\n",
        "    \"\"\"G·ªôp hai list chu·ªói, kh√¥ng ph√¢n bi·ªát hoa th∆∞·ªùng v√† tr√°nh tr√πng.\"\"\"\n",
        "    merged = []\n",
        "    seen = set()\n",
        "    for lst in (a, b):\n",
        "        if lst:\n",
        "            for item in lst:\n",
        "                if not isinstance(item, str):\n",
        "                    continue\n",
        "                key = item.lower().strip()\n",
        "                if key not in seen and key != '':\n",
        "                    seen.add(key)\n",
        "                    merged.append(item.strip())\n",
        "    return merged\n",
        "\n",
        "def merge_rows(r1, r2, debug=False, debug_counter=[0], debug_limit=10):\n",
        "    \"\"\"G·ªôp hai d√≤ng tr√πng.\"\"\"\n",
        "    def is_empty(x):\n",
        "        if x is None:\n",
        "            return True\n",
        "        if isinstance(x, (list, tuple, set)):\n",
        "            return len(x) == 0\n",
        "        if isinstance(x, str):\n",
        "            return x.strip() == ''\n",
        "        try:\n",
        "            return pd.isna(x)\n",
        "        except Exception:\n",
        "            return False\n",
        "\n",
        "    def pick(a, b):\n",
        "        return a if not is_empty(a) else b\n",
        "\n",
        "    merged = {\n",
        "        'title': pick(r1.get('title'), r2.get('title')),\n",
        "        'composers': merge_unique_case_insensitive(r1.get('composers'), r2.get('composers')),\n",
        "        'lyricists': merge_unique_case_insensitive(r1.get('lyricists'), r2.get('lyricists')),\n",
        "        'year': pick(r1.get('year'), r2.get('year')),\n",
        "        'genres': merge_unique_case_insensitive(r1.get('genres'), r2.get('genres')),\n",
        "        'lyrics': pick(r1.get('lyrics'), r2.get('lyrics')),\n",
        "        'urls': merge_unique_case_insensitive(r1.get('urls'), r2.get('urls')),\n",
        "        'source': pick(r1.get('source'), r2.get('source')),\n",
        "        'note': pick(r1.get('note'), r2.get('note')),\n",
        "    }\n",
        "\n",
        "    if debug and debug_counter[0] < debug_limit:\n",
        "        debug_counter[0] += 1\n",
        "        print(f\"\\nüß© DEBUG MERGE #{debug_counter[0]}: '{merged['title']}'\")\n",
        "        print(f\"  composers={merged['composers']} | lyricists={merged['lyricists']} | year={merged['year']}\")\n",
        "        print(f\"  genres={merged['genres']} | urls={merged['urls']}\")\n",
        "\n",
        "    return merged\n",
        "\n",
        "\n",
        "# ==== ƒê·ªåC / GHI FILE ====\n",
        "\n",
        "def read_df(path: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path)\n",
        "    for c in ['composers', 'lyricists', 'genres', 'urls']:\n",
        "        if c in df.columns:\n",
        "            df[c] = df[c].apply(parse_list_str)\n",
        "    df['comp_set'] = df['composers'].apply(get_comp_key)\n",
        "    print(f\"üìò ƒê·ªçc {path} ({len(df)} d√≤ng)\")\n",
        "    return df\n",
        "\n",
        "def write_df(df: pd.DataFrame, path: str):\n",
        "    df = df.copy()\n",
        "    for c in ['composers', 'lyricists', 'genres', 'urls']:\n",
        "        if c in df.columns:\n",
        "            df[c] = df[c].apply(str)\n",
        "    df.to_csv(path, index=False)\n",
        "    print(f\"üíæ L∆∞u: {path}\")\n",
        "\n",
        "\n",
        "# ==== G·ªòP D·ªÆ LI·ªÜU CH√çNH ====\n",
        "\n",
        "def merge_datasets(files, output_path='merged_final.csv', debug_merge=True, debug_limit=10):\n",
        "    current = read_df(files[0])\n",
        "    print(f\"\\nüöÄ B·∫Øt ƒë·∫ßu merge v·ªõi {files[0]}\")\n",
        "    debug_counter = [0]\n",
        "    total_merge = 0\n",
        "    merged_pairs = set()\n",
        "\n",
        "    for i, file in enumerate(files[1:], 2):\n",
        "        print(f\"\\nüîÑ G·ªôp file {i}/{len(files)}: {file}\")\n",
        "        new_df = read_df(file)\n",
        "        to_add = []\n",
        "        merge_count = 0\n",
        "        grouped_current = current.groupby('title')\n",
        "\n",
        "        for _, row in new_df.iterrows():\n",
        "            title_key = row['title']\n",
        "            same_title = grouped_current.get_group(title_key) if title_key in grouped_current.groups else None\n",
        "\n",
        "            if same_title is None or same_title.empty:\n",
        "                to_add.append(row)\n",
        "                continue\n",
        "\n",
        "            matched = False\n",
        "            for idx, cand in same_title.iterrows():\n",
        "                comp_overlap = bool(cand['comp_set'] & row['comp_set'])\n",
        "                # ch·ªâ c·∫ßn tr√πng √≠t nh·∫•t 1 composer l√† merge\n",
        "                if comp_overlap:\n",
        "                    merged = merge_rows(cand, row, debug=debug_merge, debug_counter=debug_counter, debug_limit=debug_limit)\n",
        "                    for col, val in merged.items():\n",
        "                        current.at[idx, col] = val\n",
        "                    current.at[idx, 'comp_set'] = get_comp_key(current.at[idx, 'composers'])\n",
        "                    matched = True\n",
        "                    merge_count += 1\n",
        "                    merged_pairs.add(f\"{cand['title']}::{','.join(cand['composers'])}\")\n",
        "                    break\n",
        "\n",
        "            if not matched:\n",
        "                to_add.append(row)\n",
        "\n",
        "        if to_add:\n",
        "            current = pd.concat([current, pd.DataFrame(to_add)], ignore_index=True)\n",
        "\n",
        "        print(f\"‚úÖ ƒê√£ merge {merge_count}, th√™m {len(to_add)} d√≤ng m·ªõi.\")\n",
        "        total_merge += merge_count\n",
        "\n",
        "    final = current.drop(columns=['comp_set'])\n",
        "    write_df(final, output_path)\n",
        "    print(\"\\nüìä T·ªîNG K·∫æT:\")\n",
        "    print(f\"   T·ªïng s·ªë b√†i merge: {total_merge}\")\n",
        "    print(f\"   T·ªïng s·ªë b√†i sau merge: {len(final)}\")\n",
        "    return final, merged_pairs\n",
        "\n",
        "\n",
        "# ==== DEMO ====\n",
        "\n",
        "files = [\n",
        "    'N01_hopamviet_final.csv',\n",
        "    'N02_timbaihat_final.csv',\n",
        "    'N03_loibaihat_final.csv',\n",
        "    'N04_nhacvn_final.csv',\n",
        "    'N04_tkaraoke_final.csv',\n",
        "    'N05_timbaihat_final.csv'\n",
        "]\n",
        "\n",
        "result, merged = merge_datasets(\n",
        "    files,\n",
        "    output_path='merged_final.csv',\n",
        "    debug_merge=True,\n",
        "    debug_limit=3\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0-hA1VdqV-M"
      },
      "source": [
        "# Merge c√°ch 2 (ƒë·ªô t∆∞∆°ng ƒë·ªìng lyric > 70%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "c5IaGeuR6Vcz",
        "outputId": "7003f8f6-52cf-43e6-8a86-ceab1e8fb512"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìò ƒê·ªçc d·ªØ li·ªáu merge tr∆∞·ªõc ƒë√≥: merged_final.csv (129967 d√≤ng)\n",
            "‚ö° B·∫Øt ƒë·∫ßu merge b·∫±ng multiprocessing (2 cores)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 6/1000 [15:03<41:35:54, 150.66s/it]Process ForkPoolWorker-7:\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4007401261.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;31m# ==== DEMO ====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m df_result = merge_by_lyrics(\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0minput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'merged_final.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'merged_final_lyric.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4007401261.py\u001b[0m in \u001b[0;36mmerge_by_lyrics\u001b[0;34m(input_path, output_path, lyric_threshold, n_process, debug_limit)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_process\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mall_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_bucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuckets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuckets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mall_pairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from rapidfuzz import fuzz\n",
        "from tqdm import tqdm\n",
        "\n",
        "def merge_unique_case_insensitive(a, b):\n",
        "    merged = []\n",
        "    seen = set()\n",
        "    for lst in (a, b):\n",
        "        if lst:\n",
        "            for item in lst:\n",
        "                if not isinstance(item, str):\n",
        "                    continue\n",
        "                key = item.lower().strip()\n",
        "                if key not in seen and key != '':\n",
        "                    seen.add(key)\n",
        "                    merged.append(item.strip())\n",
        "    return merged\n",
        "\n",
        "\n",
        "def merge_rows_lyric(r1, r2, debug=False, debug_counter=[0], debug_limit=10):\n",
        "    \"\"\"G·ªôp 2 d√≤ng d·ª±a tr√™n lyric gi·ªëng nhau.\"\"\"\n",
        "    def is_empty(x):\n",
        "        if x is None:\n",
        "            return True\n",
        "        if isinstance(x, (list, tuple, set)):\n",
        "            return len(x) == 0\n",
        "        if isinstance(x, str):\n",
        "            return x.strip() == ''\n",
        "        try:\n",
        "            return pd.isna(x)\n",
        "        except Exception:\n",
        "            return False\n",
        "    def pick(a, b):\n",
        "        return a if not is_empty(a) else b\n",
        "\n",
        "    merged = {\n",
        "        'title': pick(r1.get('title'), r2.get('title')),\n",
        "        'composers': merge_unique_case_insensitive(r1.get('composers'), r2.get('composers')),\n",
        "        'lyricists': merge_unique_case_insensitive(r1.get('lyricists'), r2.get('lyricists')),\n",
        "        'year': pick(r1.get('year'), r2.get('year')),\n",
        "        'genres': merge_unique_case_insensitive(r1.get('genres'), r2.get('genres')),\n",
        "        'lyrics': pick(r1.get('lyrics'), r2.get('lyrics')),\n",
        "        'urls': merge_unique_case_insensitive(r1.get('urls'), r2.get('urls')),\n",
        "        'source': pick(r1.get('source'), r2.get('source')),\n",
        "        'note': pick(r1.get('note'), r2.get('note'))\n",
        "    }\n",
        "\n",
        "    if debug and debug_counter[0] < debug_limit:\n",
        "        debug_counter[0] += 1\n",
        "        print(f\"\\nüéµ DEBUG LYRIC MERGE #{debug_counter[0]}: '{merged['title']}'\")\n",
        "        print(f\"  composers={merged['composers']} | lyricists={merged['lyricists']}\")\n",
        "        print(f\"  genres={merged['genres']} | urls={merged['urls']}\")\n",
        "    return merged\n",
        "\n",
        "\n",
        "def merge_by_lyrics(df, output_path='merged_final_lyric.csv', lyric_threshold=70, debug_merge=True, debug_limit=5):\n",
        "    print(f\"üìò ƒê·ªçc d·ªØ li·ªáu merge tr∆∞·ªõc ƒë√≥ ({len(df)} d√≤ng)\")\n",
        "\n",
        "    debug_counter = [0]\n",
        "    total_merge = 0\n",
        "    merged_idx = set()\n",
        "    merged_rows = []\n",
        "\n",
        "    df = df.reset_index(drop=True)\n",
        "\n",
        "    # === TH√äM PROGRESS BAR ===\n",
        "    for i in tqdm(range(len(df)), desc=f\"üîç So kh·ªõp lyric ‚â•{lyric_threshold}%\"):\n",
        "        if i in merged_idx:\n",
        "            continue\n",
        "        row_i = df.iloc[i]\n",
        "        lyrics_i = str(row_i.get('lyrics', '')).strip()\n",
        "        if not lyrics_i:\n",
        "            merged_rows.append(row_i)\n",
        "            continue\n",
        "\n",
        "        matched = False\n",
        "        for j in range(i + 1, len(df)):\n",
        "            if j in merged_idx:\n",
        "                continue\n",
        "            row_j = df.iloc[j]\n",
        "            lyrics_j = str(row_j.get('lyrics', '')).strip()\n",
        "            if not lyrics_j:\n",
        "                continue\n",
        "\n",
        "            sim = fuzz.partial_ratio(lyrics_i, lyrics_j)\n",
        "            if sim >= lyric_threshold:\n",
        "                merged = merge_rows_lyric(\n",
        "                    row_i, row_j,\n",
        "                    debug=debug_merge,\n",
        "                    debug_counter=debug_counter,\n",
        "                    debug_limit=debug_limit\n",
        "                )\n",
        "                merged_rows.append(pd.Series(merged))\n",
        "                merged_idx.add(j)\n",
        "                matched = True\n",
        "                total_merge += 1\n",
        "                break\n",
        "\n",
        "        if not matched:\n",
        "            merged_rows.append(row_i)\n",
        "\n",
        "    merged_df = pd.DataFrame(merged_rows)\n",
        "    print(f\"\\n‚úÖ ƒê√£ merge {total_merge} c·∫∑p b√†i h√°t d·ª±a tr√™n lyric ‚â• {lyric_threshold}%\")\n",
        "    merged_df.to_csv(output_path, index=False)\n",
        "    print(f\"üíæ L∆∞u k·∫øt qu·∫£: {output_path}\")\n",
        "    print(f\"üìä T·ªïng s·ªë b√†i sau merge: {len(merged_df)}\")\n",
        "    return merged_df\n",
        "\n",
        "\n",
        "# ==== DEMO CH·∫†Y ====\n",
        "df = pd.read_csv(\"merged_final.csv\")\n",
        "df['composers'] = df['composers'].apply(eval)\n",
        "df['lyricists'] = df['lyricists'].apply(eval)\n",
        "df['genres'] = df['genres'].apply(eval)\n",
        "df['urls'] = df['urls'].apply(eval)\n",
        "\n",
        "merged_df = merge_by_lyrics(\n",
        "    df,\n",
        "    output_path='merged_final_lyric.csv',\n",
        "    lyric_threshold=70,\n",
        "    debug_merge=True,\n",
        "    debug_limit=3\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "T·ªëi ∆∞u c√°ch Merge 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from rapidfuzz import fuzz\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import os\n",
        "import json\n",
        "import hashlib\n",
        "\n",
        "# ==================== LOGGING CONFIG ====================\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s | %(levelname)-8s | %(message)s\",\n",
        "    datefmt=\"%H:%M:%S\",\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"lyrics_merge.log\", encoding='utf-8'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ==================== CHECKPOINT MANAGER ====================\n",
        "class CheckpointManager:\n",
        "    def __init__(self, checkpoint_dir='checkpoints_lyric'):\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "        self.checkpoint_file = os.path.join(checkpoint_dir, 'merge_state.json')\n",
        "        self.data_checkpoint = os.path.join(checkpoint_dir, 'merged_data.csv')\n",
        "        \n",
        "    def save(self, merged_rows, merged_idx, current_idx, total_merge):\n",
        "        \"\"\"L∆∞u checkpoint\"\"\"\n",
        "        state = {\n",
        "            'current_idx': current_idx,\n",
        "            'merged_idx': list(merged_idx),\n",
        "            'total_merge': total_merge,\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        }\n",
        "        \n",
        "        # L∆∞u state\n",
        "        with open(self.checkpoint_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(state, f, indent=2)\n",
        "        \n",
        "        # L∆∞u data\n",
        "        temp_df = pd.DataFrame(merged_rows)\n",
        "        temp_df.to_csv(self.data_checkpoint, index=False, encoding='utf-8-sig')\n",
        "        \n",
        "        logger.info(f\"üíæ Checkpoint saved at index {current_idx}\")\n",
        "    \n",
        "    def load(self):\n",
        "        \"\"\"T·∫£i checkpoint\"\"\"\n",
        "        if not os.path.exists(self.checkpoint_file):\n",
        "            return None\n",
        "        \n",
        "        with open(self.checkpoint_file, 'r', encoding='utf-8') as f:\n",
        "            state = json.load(f)\n",
        "        \n",
        "        if os.path.exists(self.data_checkpoint):\n",
        "            merged_rows = pd.read_csv(self.data_checkpoint, encoding='utf-8-sig').to_dict('records')\n",
        "            logger.info(f\"‚úÖ Loaded checkpoint from index {state['current_idx']}\")\n",
        "            return state, merged_rows\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def clear(self):\n",
        "        \"\"\"X√≥a checkpoint\"\"\"\n",
        "        if os.path.exists(self.checkpoint_file):\n",
        "            os.remove(self.checkpoint_file)\n",
        "        if os.path.exists(self.data_checkpoint):\n",
        "            os.remove(self.data_checkpoint)\n",
        "        logger.info(\"üóëÔ∏è Checkpoint cleared\")\n",
        "\n",
        "\n",
        "# ==================== HELPER FUNCTIONS ====================\n",
        "def merge_unique_case_insensitive(a, b):\n",
        "    \"\"\"Merge 2 list, lo·∫°i b·ªè tr√πng l·∫∑p (case-insensitive)\"\"\"\n",
        "    merged = []\n",
        "    seen = set()\n",
        "    for lst in (a, b):\n",
        "        if lst:\n",
        "            for item in lst:\n",
        "                if not isinstance(item, str):\n",
        "                    continue\n",
        "                key = item.lower().strip()\n",
        "                if key not in seen and key != '':\n",
        "                    seen.add(key)\n",
        "                    merged.append(item.strip())\n",
        "    return merged\n",
        "\n",
        "\n",
        "def is_empty(x):\n",
        "    \"\"\"Ki·ªÉm tra gi√° tr·ªã r·ªóng\"\"\"\n",
        "    if x is None:\n",
        "        return True\n",
        "    if isinstance(x, (list, tuple, set)):\n",
        "        return len(x) == 0\n",
        "    if isinstance(x, str):\n",
        "        return x.strip() == ''\n",
        "    try:\n",
        "        return pd.isna(x)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "def pick(a, b):\n",
        "    \"\"\"Ch·ªçn gi√° tr·ªã kh√¥ng r·ªóng\"\"\"\n",
        "    return a if not is_empty(a) else b\n",
        "\n",
        "\n",
        "def merge_rows_lyric(r1, r2, debug=False):\n",
        "    \"\"\"G·ªôp 2 d√≤ng d·ª±a tr√™n lyric gi·ªëng nhau\"\"\"\n",
        "    merged = {\n",
        "        'title': pick(r1.get('title'), r2.get('title')),\n",
        "        'composers': merge_unique_case_insensitive(r1.get('composers'), r2.get('composers')),\n",
        "        'lyricists': merge_unique_case_insensitive(r1.get('lyricists'), r2.get('lyricists')),\n",
        "        'year': pick(r1.get('year'), r2.get('year')),\n",
        "        'genres': merge_unique_case_insensitive(r1.get('genres'), r2.get('genres')),\n",
        "        'lyrics': pick(r1.get('lyrics'), r2.get('lyrics')),\n",
        "        'urls': merge_unique_case_insensitive(r1.get('urls'), r2.get('urls')),\n",
        "        'source': pick(r1.get('source'), r2.get('source')),\n",
        "        'note': pick(r1.get('note'), r2.get('note'))\n",
        "    }\n",
        "    \n",
        "    if debug:\n",
        "        logger.debug(f\"Merged: {merged['title']} | composers={len(merged['composers'])}, urls={len(merged['urls'])}\")\n",
        "    \n",
        "    return merged\n",
        "\n",
        "\n",
        "def get_lyrics_hash(lyrics):\n",
        "    \"\"\"T·∫°o hash t·ª´ lyrics ƒë·ªÉ tƒÉng t·ªëc so s√°nh\"\"\"\n",
        "    if not lyrics or not isinstance(lyrics, str):\n",
        "        return None\n",
        "    clean = lyrics.lower().strip()[:100]  # Ch·ªâ l·∫•y 100 k√Ω t·ª± ƒë·∫ßu\n",
        "    return hashlib.md5(clean.encode()).hexdigest()\n",
        "\n",
        "\n",
        "# ==================== MAIN MERGE FUNCTION ====================\n",
        "def merge_by_lyrics(df, \n",
        "                    output_path='merged_final_lyric.csv',\n",
        "                    lyric_threshold=70,\n",
        "                    checkpoint_interval=500,\n",
        "                    use_hash_optimization=True,\n",
        "                    resume_from_checkpoint=True):\n",
        "    \n",
        "    start_time = datetime.now()\n",
        "    logger.info(\"=\"*60)\n",
        "    logger.info(\"üéµ B·∫ÆT ƒê·∫¶U MERGE LYRICS\")\n",
        "    logger.info(f\"üìä D·ªØ li·ªáu: {len(df)} d√≤ng\")\n",
        "    logger.info(f\"üéØ Ng∆∞·ª°ng: {lyric_threshold}%\")\n",
        "    logger.info(\"=\"*60)\n",
        "    \n",
        "    # Kh·ªüi t·∫°o checkpoint manager\n",
        "    ckpt = CheckpointManager()\n",
        "    \n",
        "    # Th·ª≠ load checkpoint\n",
        "    checkpoint_data = None\n",
        "    if resume_from_checkpoint:\n",
        "        checkpoint_data = ckpt.load()\n",
        "    \n",
        "    df = df.reset_index(drop=True)\n",
        "    \n",
        "    # Kh·ªüi t·∫°o bi·∫øn\n",
        "    if checkpoint_data:\n",
        "        state, merged_rows = checkpoint_data\n",
        "        merged_idx = set(state['merged_idx'])\n",
        "        total_merge = state['total_merge']\n",
        "        start_idx = state['current_idx'] + 1\n",
        "        logger.info(f\"üîÑ Ti·∫øp t·ª•c t·ª´ index {start_idx}, ƒë√£ merge {total_merge} c·∫∑p\")\n",
        "    else:\n",
        "        merged_rows = []\n",
        "        merged_idx = set()\n",
        "        total_merge = 0\n",
        "        start_idx = 0\n",
        "    \n",
        "    # T·ªëi ∆∞u: T·∫°o hash map cho lyrics (n·∫øu b·∫≠t)\n",
        "    lyrics_hash_map = {}\n",
        "    if use_hash_optimization:\n",
        "        logger.info(\"üîß T·∫°o hash map ƒë·ªÉ t·ªëi ∆∞u t√¨m ki·∫øm...\")\n",
        "        for i in range(len(df)):\n",
        "            lyrics = str(df.iloc[i].get('lyrics', '')).strip()\n",
        "            if lyrics:\n",
        "                h = get_lyrics_hash(lyrics)\n",
        "                if h:\n",
        "                    if h not in lyrics_hash_map:\n",
        "                        lyrics_hash_map[h] = []\n",
        "                    lyrics_hash_map[h].append(i)\n",
        "        logger.info(f\"‚úÖ ƒê√£ t·∫°o {len(lyrics_hash_map)} hash groups\")\n",
        "    \n",
        "    # Main loop v·ªõi progress bar\n",
        "    for i in tqdm(range(start_idx, len(df)), desc=f\"üîç Merge lyric ‚â•{lyric_threshold}%\", initial=start_idx, total=len(df)):\n",
        "        if i in merged_idx:\n",
        "            continue\n",
        "        \n",
        "        row_i = df.iloc[i]\n",
        "        lyrics_i = str(row_i.get('lyrics', '')).strip()\n",
        "        \n",
        "        if not lyrics_i:\n",
        "            merged_rows.append(row_i)\n",
        "            continue\n",
        "        \n",
        "        matched = False\n",
        "        \n",
        "        # T·ªëi ∆∞u: Ch·ªâ so s√°nh v·ªõi c√°c b√†i c√≥ hash t∆∞∆°ng t·ª±\n",
        "        if use_hash_optimization:\n",
        "            h = get_lyrics_hash(lyrics_i)\n",
        "            candidates = lyrics_hash_map.get(h, [i])\n",
        "            search_range = [j for j in candidates if j > i and j not in merged_idx]\n",
        "        else:\n",
        "            search_range = range(i + 1, len(df))\n",
        "        \n",
        "        for j in search_range:\n",
        "            if j in merged_idx:\n",
        "                continue\n",
        "            \n",
        "            row_j = df.iloc[j]\n",
        "            lyrics_j = str(row_j.get('lyrics', '')).strip()\n",
        "            \n",
        "            if not lyrics_j:\n",
        "                continue\n",
        "            \n",
        "            # T·ªëi ∆∞u: Ki·ªÉm tra ƒë·ªô d√†i tr∆∞·ªõc khi so s√°nh\n",
        "            len_diff = abs(len(lyrics_i) - len(lyrics_j)) / max(len(lyrics_i), len(lyrics_j))\n",
        "            if len_diff > 0.5:  # N·∫øu ch√™nh l·ªách >50% ƒë·ªô d√†i th√¨ b·ªè qua\n",
        "                continue\n",
        "            \n",
        "            sim = fuzz.partial_ratio(lyrics_i, lyrics_j)\n",
        "            \n",
        "            if sim >= lyric_threshold:\n",
        "                merged = merge_rows_lyric(row_i, row_j, debug=False)\n",
        "                merged_rows.append(pd.Series(merged))\n",
        "                merged_idx.add(j)\n",
        "                matched = True\n",
        "                total_merge += 1\n",
        "                \n",
        "                logger.debug(f\"‚úì Merged pair: {i} + {j} (sim={sim}%)\")\n",
        "                break\n",
        "        \n",
        "        if not matched:\n",
        "            merged_rows.append(row_i)\n",
        "        \n",
        "        # L∆∞u checkpoint ƒë·ªãnh k·ª≥\n",
        "        if (i + 1) % checkpoint_interval == 0:\n",
        "            ckpt.save(merged_rows, merged_idx, i, total_merge)\n",
        "    \n",
        "    # T·∫°o DataFrame k·∫øt qu·∫£\n",
        "    merged_df = pd.DataFrame(merged_rows)\n",
        "    \n",
        "    # L∆∞u file cu·ªëi\n",
        "    merged_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
        "    \n",
        "    # Clear checkpoint\n",
        "    ckpt.clear()\n",
        "    \n",
        "    # Th·ªëng k√™\n",
        "    elapsed = datetime.now() - start_time\n",
        "    logger.info(\"=\"*60)\n",
        "    logger.info(f\"‚úÖ HO√ÄN T·∫§T MERGE LYRICS\")\n",
        "    logger.info(f\"üìä K·∫øt qu·∫£:\")\n",
        "    logger.info(f\"   - ƒê√£ merge: {total_merge} c·∫∑p\")\n",
        "    logger.info(f\"   - Tr∆∞·ªõc: {len(df)} b√†i\")\n",
        "    logger.info(f\"   - Sau: {len(merged_df)} b√†i\")\n",
        "    logger.info(f\"   - Gi·∫£m: {len(df) - len(merged_df)} b√†i ({(len(df)-len(merged_df))/len(df)*100:.1f}%)\")\n",
        "    logger.info(f\"‚è±Ô∏è  Th·ªùi gian: {elapsed}\")\n",
        "    logger.info(f\"üíæ File: {output_path}\")\n",
        "    logger.info(\"=\"*60)\n",
        "    \n",
        "    return merged_df\n",
        "\n",
        "\n",
        "# ==================== DEMO CH·∫†Y ====================\n",
        "if __name__ == '__main__':\n",
        "    logger.info(\"üìÇ ƒê·ªçc file merged_final.csv...\")\n",
        "    df = pd.read_csv(\"merged_final.csv\", encoding='utf-8-sig')\n",
        "    \n",
        "    # Parse list columns\n",
        "    for col in ['composers', 'lyricists', 'genres', 'urls']:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) and x.startswith('[') else [])\n",
        "    \n",
        "    # Ch·∫°y merge\n",
        "    merged_df = merge_by_lyrics(\n",
        "        df,\n",
        "        output_path='merged_final_lyric.csv',\n",
        "        lyric_threshold=70,\n",
        "        checkpoint_interval=500,  # L∆∞u m·ªói 500 d√≤ng\n",
        "        use_hash_optimization=True,  # B·∫≠t t·ªëi ∆∞u hash\n",
        "        resume_from_checkpoint=True  # T·ª± ƒë·ªông resume n·∫øu c√≥ checkpoint\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

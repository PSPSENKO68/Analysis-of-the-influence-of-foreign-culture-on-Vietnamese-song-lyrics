{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Xóa những từ tiếng anh chuẩn có trong file ten_rieng.csv",
   "id": "17b7abcffe823021"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:25:02.512782Z",
     "start_time": "2026-01-03T11:25:02.332515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import words\n",
    "\n",
    "# 1. Cấu hình file\n",
    "file_ten_rieng = 'ten_rieng.csv'          # File chứa danh sách tên riêng cần lọc\n",
    "output_file = 'ten_rieng_cleaned.csv'     # File kết quả\n",
    "\n",
    "try:\n",
    "    print(f\"Đang nạp từ điển NLTK từ: /Users/copy/nltk_data ...\")\n",
    "\n",
    "    # 2. Tạo bộ lọc từ điển (Set)\n",
    "    # Chuyển tất cả về chữ thường để so sánh chính xác (boy == Boy)\n",
    "    english_vocab = set(w.lower() for w in words.words())\n",
    "    print(f\"-> Đã nạp thành công {len(english_vocab)} từ tiếng Anh chuẩn.\")\n",
    "\n",
    "    # 3. Đọc file CSV tên riêng\n",
    "    df_names = pd.read_csv(file_ten_rieng, encoding='utf-8-sig')\n",
    "\n",
    "    # Tự động lấy tên cột đầu tiên (ví dụ: 'teen_code' hoặc 'word')\n",
    "    col_name = df_names.columns[0]\n",
    "    print(f\"\\nTổng số dòng ban đầu: {len(df_names)}\")\n",
    "\n",
    "    # 4. Định nghĩa hàm lọc\n",
    "    def is_valid_name(name):\n",
    "        # Chuyển từ cần kiểm tra về string, xóa khoảng trắng, về chữ thường\n",
    "        clean_name = str(name).strip().lower()\n",
    "\n",
    "        # Nếu từ này CÓ trong từ điển Anh -> Trả về False (để XÓA)\n",
    "        # Nếu từ này KHÔNG có -> Trả về True (để GIỮ LẠI)\n",
    "        return clean_name not in english_vocab\n",
    "\n",
    "    # 5. Áp dụng bộ lọc\n",
    "    # Giữ lại những dòng mà hàm is_valid_name trả về True\n",
    "    df_cleaned = df_names[df_names[col_name].apply(is_valid_name)]\n",
    "\n",
    "    # 6. Thống kê và Lưu file\n",
    "    so_luong_xoa = len(df_names) - len(df_cleaned)\n",
    "    df_cleaned.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Đã hoàn thành!\")\n",
    "    print(f\"Số từ bị xóa (trùng tiếng Anh): {so_luong_xoa}\")\n",
    "    print(f\"Số tên riêng còn lại: {len(df_cleaned)}\")\n",
    "    print(f\"File sạch đã lưu tại: {output_file}\")\n",
    "\n",
    "    # In thử vài từ bị xóa để kiểm tra (nếu có)\n",
    "    deleted = df_names[~df_names[col_name].apply(is_valid_name)][col_name].head(5).tolist()\n",
    "    if deleted:\n",
    "        print(f\"Ví dụ các từ đã bị xóa: {deleted}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Lỗi: Không tìm thấy file '{file_ten_rieng}' tại thư mục chạy code.\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi: {e}\")"
   ],
   "id": "536ccae32660eeda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang nạp từ điển NLTK từ: /Users/copy/nltk_data ...\n",
      "-> Đã nạp thành công 234377 từ tiếng Anh chuẩn.\n",
      "\n",
      "Tổng số dòng ban đầu: 9901\n",
      "----------------------------------------\n",
      "Đã hoàn thành!\n",
      "Số từ bị xóa (trùng tiếng Anh): 697\n",
      "Số tên riêng còn lại: 9204\n",
      "File sạch đã lưu tại: ten_rieng_cleaned.csv\n",
      "Ví dụ các từ đã bị xóa: ['Matra', 'Abraham', 'Ace', 'Adam', 'adam']\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Xóa các từ có trong phien_am.csv ra khỏi ten_rieng.csv",
   "id": "5f14a9faf8dfdb73"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:25:15.700764Z",
     "start_time": "2026-01-03T11:25:15.652362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ==============================================================================\n",
    "# CẤU HÌNH FILE\n",
    "# ==============================================================================\n",
    "file_ten_rieng = 'ten_rieng_cleaned.csv'       # File tên riêng cần làm sạch\n",
    "file_phien_am = 'phien_am.csv'         # File chứa các từ phiên âm (cần loại bỏ)\n",
    "output_file = 'ten_rieng.csv'  # File kết quả\n",
    "\n",
    "try:\n",
    "    print(\"Đang đọc dữ liệu...\")\n",
    "    # 1. Đọc file\n",
    "    # Dùng low_memory=False phòng trường hợp file lớn hoặc mix type\n",
    "    df_names = pd.read_csv(file_ten_rieng, encoding='utf-8-sig')\n",
    "    df_phien_am = pd.read_csv(file_phien_am, encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"- File tên riêng: {df_names.shape[0]} dòng\")\n",
    "    print(f\"- File phiên âm: {df_phien_am.shape[0]} dòng, {df_phien_am.shape[1]} cột\")\n",
    "\n",
    "    # 2. TẠO BLACKLIST TỪ FILE PHIÊN ÂM\n",
    "    # Vì file phiên âm có nhiều cột, ta cần \"ép phẳng\" (flatten) tất cả về 1 danh sách duy nhất\n",
    "    print(\"Đang xử lý dữ liệu phiên âm...\")\n",
    "\n",
    "    # Lấy toàn bộ dữ liệu, chuyển thành mảng 1 chiều, loại bỏ giá trị Null/NaN\n",
    "    all_phien_am_values = df_phien_am.values.flatten()\n",
    "\n",
    "    # Tạo set để tra cứu cho nhanh (convert về string chữ thường + xóa khoảng trắng thừa)\n",
    "    # set() giúp loại bỏ các từ trùng lặp trong chính file phiên âm\n",
    "    blacklist = set()\n",
    "    for val in all_phien_am_values:\n",
    "        if pd.notna(val): # Chỉ lấy nếu không phải là ô trống\n",
    "            clean_val = str(val).strip().lower()\n",
    "            if clean_val: # Nếu không phải chuỗi rỗng\n",
    "                blacklist.add(clean_val)\n",
    "\n",
    "    print(f\"-> Đã tạo danh sách đen gồm {len(blacklist)} từ phiên âm độc nhất.\")\n",
    "\n",
    "    # 3. LỌC FILE TÊN RIÊNG\n",
    "    col_name = df_names.columns[0] # Lấy cột đầu tiên của file tên riêng\n",
    "\n",
    "    def is_valid_name(name):\n",
    "        # Chuyển tên cần check về dạng chuẩn (thường, không space)\n",
    "        clean_name = str(name).strip().lower()\n",
    "        # Giữ lại nếu KHÔNG nằm trong blacklist\n",
    "        return clean_name not in blacklist\n",
    "\n",
    "    # Áp dụng bộ lọc\n",
    "    df_clean = df_names[df_names[col_name].apply(is_valid_name)]\n",
    "\n",
    "    # 4. THỐNG KÊ VÀ LƯU\n",
    "    so_luong_bi_xoa = len(df_names) - len(df_clean)\n",
    "\n",
    "    df_clean.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"HOÀN TẤT XỬ LÝ!\")\n",
    "    print(f\"Số từ bị xóa (trùng phiên âm): {so_luong_bi_xoa}\")\n",
    "    print(f\"Số tên riêng còn lại: {len(df_clean)}\")\n",
    "    print(f\"File sạch đã lưu tại: {output_file}\")\n",
    "\n",
    "    # In thử vài ví dụ bị xóa để kiểm tra\n",
    "    if so_luong_bi_xoa > 0:\n",
    "        deleted_items = df_names[~df_names[col_name].apply(is_valid_name)][col_name].head(10).tolist()\n",
    "        print(f\"\\nVí dụ các từ đã bị xóa: {deleted_items}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Lỗi không tìm thấy file: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi: {e}\")"
   ],
   "id": "44ac28f75c0413ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang đọc dữ liệu...\n",
      "- File tên riêng: 9204 dòng\n",
      "- File phiên âm: 41 dòng, 16 cột\n",
      "Đang xử lý dữ liệu phiên âm...\n",
      "-> Đã tạo danh sách đen gồm 188 từ phiên âm độc nhất.\n",
      "\n",
      "==============================\n",
      "HOÀN TẤT XỬ LÝ!\n",
      "Số từ bị xóa (trùng phiên âm): 23\n",
      "Số tên riêng còn lại: 9181\n",
      "File sạch đã lưu tại: ten_rieng_final.csv\n",
      "\n",
      "Ví dụ các từ đã bị xóa: ['A Di Đà', 'A di đà', 'Apsara', 'apsara', 'Cờ-rút-sì', 'Élysées', 'la mar de suenos', 'maxcơva', 'Métro', 'Mitsipsipi']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Xóa ten_rieng_cleaned.csv khỏi english.csv",
   "id": "8e39314f2f2396f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:25:46.407253Z",
     "start_time": "2026-01-03T11:25:46.358940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ==============================================================================\n",
    "# CẤU HÌNH FILE\n",
    "# ==============================================================================\n",
    "file_english = 'english.csv'                # File gốc (Từ điển tiếng Anh)\n",
    "file_remove = 'ten_rieng.csv'  # File chứa các từ cần xóa (Tên riêng)\n",
    "output_file = 'english_cleaned.csv'           # File kết quả sau khi lọc\n",
    "\n",
    "try:\n",
    "    print(\"Đang đọc dữ liệu...\")\n",
    "    # 1. Đọc file\n",
    "    df_eng = pd.read_csv(file_english, encoding='utf-8-sig')\n",
    "    df_rem = pd.read_csv(file_remove, encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"- File English gốc: {len(df_eng)} dòng\")\n",
    "    print(f\"- File Tên riêng (để xóa): {len(df_rem)} dòng\")\n",
    "\n",
    "    # 2. Tạo danh sách các từ cần xóa (Blacklist)\n",
    "    # Lấy cột đầu tiên của file ten_rieng, đưa về chữ thường để so sánh\n",
    "    col_rem = df_rem.columns[0]\n",
    "    remove_set = set(df_rem[col_rem].astype(str).str.strip().str.lower())\n",
    "\n",
    "    # 3. Thực hiện lọc\n",
    "    col_eng = df_eng.columns[0] # Lấy cột đầu tiên của file english\n",
    "\n",
    "    # Logic: Giữ lại những từ trong english.csv KHÔNG nằm trong remove_set\n",
    "    # Dùng ~ (NOT) và isin\n",
    "    mask = ~df_eng[col_eng].astype(str).str.strip().str.lower().isin(remove_set)\n",
    "    df_final = df_eng[mask]\n",
    "\n",
    "    # 4. Thống kê và lưu file\n",
    "    so_luong_xoa = len(df_eng) - len(df_final)\n",
    "\n",
    "    df_final.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"HOÀN TẤT!\")\n",
    "    print(f\"Số từ tiếng Anh bị xóa (do trùng tên riêng): {so_luong_xoa}\")\n",
    "    print(f\"Số từ tiếng Anh còn lại: {len(df_final)}\")\n",
    "    print(f\"File kết quả lưu tại: {output_file}\")\n",
    "\n",
    "    # In thử ví dụ\n",
    "    if so_luong_xoa > 0:\n",
    "        deleted = df_eng[~mask][col_eng].head(5).tolist()\n",
    "        print(f\"\\nVí dụ các từ đã bị xóa: {deleted}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Lỗi: Không tìm thấy file. {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi: {e}\")"
   ],
   "id": "35a549897d97901e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang đọc dữ liệu...\n",
      "- File English gốc: 14125 dòng\n",
      "- File Tên riêng (để xóa): 9181 dòng\n",
      "\n",
      "==============================\n",
      "HOÀN TẤT!\n",
      "Số từ tiếng Anh bị xóa (do trùng tên riêng): 631\n",
      "Số từ tiếng Anh còn lại: 13494\n",
      "File kết quả lưu tại: english_cleaned.csv\n",
      "\n",
      "Ví dụ các từ đã bị xóa: ['50 Cent', '52hz', '5days', '88rising', 'A1']\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Xóa phien_am.csv khỏi english_final.csv",
   "id": "e07333c1a9417c44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:27:21.751419Z",
     "start_time": "2026-01-03T11:27:21.711148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ==============================================================================\n",
    "# CẤU HÌNH FILE\n",
    "# ==============================================================================\n",
    "file_english = 'english_cleaned.csv'      # File tiếng Anh (đã lọc tên riêng ở bước trước)\n",
    "file_phien_am = 'phien_am.csv'          # File phiên âm (chứa nhiều cột)\n",
    "output_file = 'english_really_final.csv' # File kết quả cuối cùng\n",
    "\n",
    "try:\n",
    "    print(\"Đang đọc dữ liệu...\")\n",
    "    # 1. Đọc file\n",
    "    df_eng = pd.read_csv(file_english, encoding='utf-8-sig')\n",
    "    df_phien_am = pd.read_csv(file_phien_am, encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"- File English hiện tại: {len(df_eng)} dòng\")\n",
    "    print(f\"- File Phiên âm: {df_phien_am.shape[0]} dòng, {df_phien_am.shape[1]} cột\")\n",
    "\n",
    "    # 2. Xử lý file Phiên âm -> Tạo Blacklist\n",
    "    # Gom tất cả các cột lại thành 1 danh sách duy nhất\n",
    "    print(\"Đang tạo danh sách đen từ file phiên âm...\")\n",
    "    all_phien_am_values = df_phien_am.values.flatten()\n",
    "\n",
    "    # Tạo set blacklist (chuẩn hóa về chữ thường để so sánh)\n",
    "    blacklist = set()\n",
    "    for val in all_phien_am_values:\n",
    "        if pd.notna(val): # Bỏ qua giá trị rỗng\n",
    "            clean_val = str(val).strip().lower()\n",
    "            if clean_val:\n",
    "                blacklist.add(clean_val)\n",
    "\n",
    "    print(f\"-> Blacklist phiên âm có {len(blacklist)} từ.\")\n",
    "\n",
    "    # 3. Lọc file English\n",
    "    col_eng = df_eng.columns[0] # Lấy cột chứa từ tiếng Anh\n",
    "\n",
    "    # Logic: Giữ lại từ nếu nó KHÔNG nằm trong blacklist\n",
    "    # (So sánh ở dạng lowercase)\n",
    "    mask = ~df_eng[col_eng].astype(str).str.strip().str.lower().isin(blacklist)\n",
    "    df_final = df_eng[mask]\n",
    "\n",
    "    # 4. Lưu kết quả\n",
    "    so_luong_xoa = len(df_eng) - len(df_final)\n",
    "\n",
    "    df_final.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"HOÀN TẤT XỬ LÝ!\")\n",
    "    print(f\"Số từ tiếng Anh bị xóa (do trùng phiên âm): {so_luong_xoa}\")\n",
    "    print(f\"Số lượng từ tiếng Anh cuối cùng: {len(df_final)}\")\n",
    "    print(f\"File đã lưu tại: {output_file}\")\n",
    "\n",
    "    # In ví dụ các từ bị xóa\n",
    "    if so_luong_xoa > 0:\n",
    "        deleted = df_eng[~mask][col_eng].head(10).tolist()\n",
    "        print(f\"\\nVí dụ các từ bị xóa khỏi từ điển Anh: {deleted}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Lỗi: Không tìm thấy file. {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi: {e}\")"
   ],
   "id": "cc94412b449c62d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang đọc dữ liệu...\n",
      "- File English hiện tại: 13494 dòng\n",
      "- File Phiên âm: 41 dòng, 16 cột\n",
      "Đang tạo danh sách đen từ file phiên âm...\n",
      "-> Blacklist phiên âm có 188 từ.\n",
      "\n",
      "==============================\n",
      "HOÀN TẤT XỬ LÝ!\n",
      "Số từ tiếng Anh bị xóa (do trùng phiên âm): 18\n",
      "Số lượng từ tiếng Anh cuối cùng: 13476\n",
      "File đã lưu tại: english_really_final.csv\n",
      "\n",
      "Ví dụ các từ bị xóa khỏi từ điển Anh: ['alleluia', 'baby', 'Bioneun georieseo', 'ciao', 'ghita', 'Je taimais', 'kimono', 'Konnichiwa', 'Namo', 'oppa']\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Xóa english_really_final.csv khỏi phien_am.csv",
   "id": "4571cd43efe6decd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:29:45.902846Z",
     "start_time": "2026-01-03T11:29:45.761913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import words\n",
    "\n",
    "# 1. Cấu hình file\n",
    "file_ten_rieng = 'phien_am.csv'          # File chứa danh sách tên riêng cần lọc\n",
    "output_file = 'phien_am_cleaned.csv'     # File kết quả\n",
    "\n",
    "try:\n",
    "    print(f\"Đang nạp từ điển NLTK từ: /Users/copy/nltk_data ...\")\n",
    "\n",
    "    # 2. Tạo bộ lọc từ điển (Set)\n",
    "    # Chuyển tất cả về chữ thường để so sánh chính xác (boy == Boy)\n",
    "    english_vocab = set(w.lower() for w in words.words())\n",
    "    print(f\"-> Đã nạp thành công {len(english_vocab)} từ tiếng Anh chuẩn.\")\n",
    "\n",
    "    # 3. Đọc file CSV tên riêng\n",
    "    df_names = pd.read_csv(file_ten_rieng, encoding='utf-8-sig')\n",
    "\n",
    "    # Tự động lấy tên cột đầu tiên (ví dụ: 'teen_code' hoặc 'word')\n",
    "    col_name = df_names.columns[0]\n",
    "    print(f\"\\nTổng số dòng ban đầu: {len(df_names)}\")\n",
    "\n",
    "    # 4. Định nghĩa hàm lọc\n",
    "    def is_valid_name(name):\n",
    "        # Chuyển từ cần kiểm tra về string, xóa khoảng trắng, về chữ thường\n",
    "        clean_name = str(name).strip().lower()\n",
    "\n",
    "        # Nếu từ này CÓ trong từ điển Anh -> Trả về False (để XÓA)\n",
    "        # Nếu từ này KHÔNG có -> Trả về True (để GIỮ LẠI)\n",
    "        return clean_name not in english_vocab\n",
    "\n",
    "    # 5. Áp dụng bộ lọc\n",
    "    # Giữ lại những dòng mà hàm is_valid_name trả về True\n",
    "    df_cleaned = df_names[df_names[col_name].apply(is_valid_name)]\n",
    "\n",
    "    # 6. Thống kê và Lưu file\n",
    "    so_luong_xoa = len(df_names) - len(df_cleaned)\n",
    "    df_cleaned.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Đã hoàn thành!\")\n",
    "    print(f\"Số từ bị xóa (trùng tiếng Anh): {so_luong_xoa}\")\n",
    "    print(f\"Số tên riêng còn lại: {len(df_cleaned)}\")\n",
    "    print(f\"File sạch đã lưu tại: {output_file}\")\n",
    "\n",
    "    # In thử vài từ bị xóa để kiểm tra (nếu có)\n",
    "    deleted = df_names[~df_names[col_name].apply(is_valid_name)][col_name].head(5).tolist()\n",
    "    if deleted:\n",
    "        print(f\"Ví dụ các từ đã bị xóa: {deleted}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Lỗi: Không tìm thấy file '{file_ten_rieng}' tại thư mục chạy code.\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi: {e}\")"
   ],
   "id": "44774aa18751a8a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang nạp từ điển NLTK từ: /Users/copy/nltk_data ...\n",
      "-> Đã nạp thành công 234377 từ tiếng Anh chuẩn.\n",
      "\n",
      "Tổng số dòng ban đầu: 41\n",
      "----------------------------------------\n",
      "Đã hoàn thành!\n",
      "Số từ bị xóa (trùng tiếng Anh): 40\n",
      "Số tên riêng còn lại: 1\n",
      "File sạch đã lưu tại: phien_am_cleaned.csv\n",
      "Ví dụ các từ đã bị xóa: [nan, nan, nan, nan, nan]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:42:43.166381Z",
     "start_time": "2026-01-03T11:42:43.117549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ==============================================================================\n",
    "# CẤU HÌNH INPUT (Tên file kết quả cuối cùng của bạn)\n",
    "# ==============================================================================\n",
    "file_english = 'english.csv'\n",
    "file_phien_am = 'phien_am.csv'\n",
    "file_ten_rieng = 'ten_rieng.csv'\n",
    "\n",
    "try:\n",
    "    print(\"Đang tải 3 file để đối chiếu chéo...\")\n",
    "\n",
    "    # 1. Đọc dữ liệu\n",
    "    df_eng = pd.read_csv(file_english, encoding='utf-8-sig')\n",
    "    df_pa = pd.read_csv(file_phien_am, encoding='utf-8-sig')\n",
    "    df_tr = pd.read_csv(file_ten_rieng, encoding='utf-8-sig')\n",
    "\n",
    "    # 2. Tạo 3 tập hợp (SET) chuẩn hóa\n",
    "    # Hàm helper để chuẩn hóa (lowercase, strip, bỏ nan)\n",
    "    def get_clean_set(df_input):\n",
    "        # Nếu là dataframe nhiều cột (như phien_am), flatten trước\n",
    "        values = df_input.values.flatten()\n",
    "        clean_set = set()\n",
    "        for val in values:\n",
    "            if pd.notna(val):\n",
    "                s = str(val).strip().lower()\n",
    "                if s: clean_set.add(s)\n",
    "        return clean_set\n",
    "\n",
    "    set_eng = get_clean_set(df_eng)\n",
    "    set_pa = get_clean_set(df_pa)\n",
    "    set_tr = get_clean_set(df_tr)\n",
    "\n",
    "    print(f\"-> Số lượng từ: English={len(set_eng)}, Phiên Âm={len(set_pa)}, Tên Riêng={len(set_tr)}\")\n",
    "\n",
    "    # 3. Tìm điểm trùng lặp (Intersection)\n",
    "    # A & B trả về các phần tử chung của A và B\n",
    "    Trung_Eng_vs_PA = set_eng & set_pa\n",
    "    Trung_Eng_vs_TR = set_eng & set_tr\n",
    "    Trung_PA_vs_TR  = set_pa  & set_tr\n",
    "\n",
    "    # 4. Báo cáo kết quả\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"KẾT QUẢ KIỂM TRA ĐỘC LẬP (DISJOINT CHECK)\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    # Check 1: English vs Phiên Âm\n",
    "    if len(Trung_Eng_vs_PA) == 0:\n",
    "        print(\"✅ English và Phiên Âm: SẠCH (Không trùng).\")\n",
    "    else:\n",
    "        print(f\"❌ CẢNH BÁO: Còn {len(Trung_Eng_vs_PA)} từ trùng giữa English và Phiên Âm.\")\n",
    "        print(f\"   Ví dụ: {list(Trung_Eng_vs_PA)[:5]}\")\n",
    "\n",
    "    # Check 2: English vs Tên Riêng\n",
    "    if len(Trung_Eng_vs_TR) == 0:\n",
    "        print(\"✅ English và Tên Riêng: SẠCH (Không trùng).\")\n",
    "    else:\n",
    "        print(f\"❌ CẢNH BÁO: Còn {len(Trung_Eng_vs_TR)} từ trùng giữa English và Tên Riêng.\")\n",
    "        print(f\"   Ví dụ: {list(Trung_Eng_vs_TR)[:5]}\")\n",
    "\n",
    "    # Check 3: Phiên Âm vs Tên Riêng\n",
    "    if len(Trung_PA_vs_TR) == 0:\n",
    "        print(\"✅ Phiên Âm và Tên Riêng: SẠCH (Không trùng).\")\n",
    "    else:\n",
    "        print(f\"❌ CẢNH BÁO: Còn {len(Trung_PA_vs_TR)} từ trùng giữa Phiên Âm và Tên Riêng.\")\n",
    "        print(f\"   Ví dụ: {list(Trung_PA_vs_TR)[:5]}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi: {e}\")"
   ],
   "id": "5d6be910636e0725",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tải 3 file để đối chiếu chéo...\n",
      "-> Số lượng từ: English=9964, Phiên Âm=188, Tên Riêng=8423\n",
      "\n",
      "========================================\n",
      "KẾT QUẢ KIỂM TRA ĐỘC LẬP (DISJOINT CHECK)\n",
      "========================================\n",
      "✅ English và Phiên Âm: SẠCH (Không trùng).\n",
      "✅ English và Tên Riêng: SẠCH (Không trùng).\n",
      "✅ Phiên Âm và Tên Riêng: SẠCH (Không trùng).\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "xóa các từ trong ntlk chuẩn khỏi english_really_final.csv",
   "id": "caa7b8847d990fc9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:37:23.971971Z",
     "start_time": "2026-01-03T11:37:23.791915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import words\n",
    "\n",
    "# 1. Cấu hình file\n",
    "file_ten_rieng = 'english_really_final.csv'          # File chứa danh sách tên riêng cần lọc\n",
    "output_file = 'english.csv'  # File kết quả\n",
    "\n",
    "try:\n",
    "    print(f\"Đang nạp từ điển NLTK từ: /Users/copy/nltk_data ...\")\n",
    "\n",
    "    # 2. Tạo bộ lọc từ điển (Set)\n",
    "    # Chuyển tất cả về chữ thường để so sánh chính xác (boy == Boy)\n",
    "    english_vocab = set(w.lower() for w in words.words())\n",
    "    print(f\"-> Đã nạp thành công {len(english_vocab)} từ tiếng Anh chuẩn.\")\n",
    "\n",
    "    # 3. Đọc file CSV tên riêng\n",
    "    df_names = pd.read_csv(file_ten_rieng, encoding='utf-8-sig')\n",
    "\n",
    "    # Tự động lấy tên cột đầu tiên (ví dụ: 'teen_code' hoặc 'word')\n",
    "    col_name = df_names.columns[0]\n",
    "    print(f\"\\nTổng số dòng ban đầu: {len(df_names)}\")\n",
    "\n",
    "    # 4. Định nghĩa hàm lọc\n",
    "    def is_valid_name(name):\n",
    "        # Chuyển từ cần kiểm tra về string, xóa khoảng trắng, về chữ thường\n",
    "        clean_name = str(name).strip().lower()\n",
    "\n",
    "        # Nếu từ này CÓ trong từ điển Anh -> Trả về False (để XÓA)\n",
    "        # Nếu từ này KHÔNG có -> Trả về True (để GIỮ LẠI)\n",
    "        return clean_name not in english_vocab\n",
    "\n",
    "    # 5. Áp dụng bộ lọc\n",
    "    # Giữ lại những dòng mà hàm is_valid_name trả về True\n",
    "    df_cleaned = df_names[df_names[col_name].apply(is_valid_name)]\n",
    "\n",
    "    # 6. Thống kê và Lưu file\n",
    "    so_luong_xoa = len(df_names) - len(df_cleaned)\n",
    "    df_cleaned.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Đã hoàn thành!\")\n",
    "    print(f\"Số từ bị xóa (trùng tiếng Anh): {so_luong_xoa}\")\n",
    "    print(f\"Số tên riêng còn lại: {len(df_cleaned)}\")\n",
    "    print(f\"File sạch đã lưu tại: {output_file}\")\n",
    "\n",
    "    # In thử vài từ bị xóa để kiểm tra (nếu có)\n",
    "    deleted = df_names[~df_names[col_name].apply(is_valid_name)][col_name].head(5).tolist()\n",
    "    if deleted:\n",
    "        print(f\"Ví dụ các từ đã bị xóa: {deleted}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Lỗi: Không tìm thấy file '{file_ten_rieng}' tại thư mục chạy code.\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi: {e}\")"
   ],
   "id": "589bd7e723c9dc6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang nạp từ điển NLTK từ: /Users/copy/nltk_data ...\n",
      "-> Đã nạp thành công 234377 từ tiếng Anh chuẩn.\n",
      "\n",
      "Tổng số dòng ban đầu: 13476\n",
      "----------------------------------------\n",
      "Đã hoàn thành!\n",
      "Số từ bị xóa (trùng tiếng Anh): 3512\n",
      "Số tên riêng còn lại: 9964\n",
      "File sạch đã lưu tại: english_out_standard.csv\n",
      "Ví dụ các từ đã bị xóa: ['a', 'aam', 'abandon', 'abandoned', 'ability']\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dùng thư viện từ tiếng việt chuẩn nlp , loại những từ có trong thư viện ra khỏi han_viet.csv",
   "id": "58b0e276f511e0b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T12:30:04.836290Z",
     "start_time": "2026-01-03T12:30:04.329019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# ==============================================================================\n",
    "# CẤU HÌNH\n",
    "# ==============================================================================\n",
    "file_input = 'hanviet_dictionary.csv'             # File đầu vào\n",
    "output_file = 'han_viet_filtered.csv'   # File kết quả\n",
    "target_source = 'phongp-hanviet-pinyin' # Nguồn cần kiểm tra để lọc\n",
    "\n",
    "# Link từ điển tiếng Việt chuẩn (Viet74K)\n",
    "URL_VIETNAMESE_DICT = \"https://raw.githubusercontent.com/duyet/vietnamese-wordlist/master/Viet74K.txt\"\n",
    "\n",
    "try:\n",
    "    # 1. Tải từ điển Tiếng Việt chuẩn\n",
    "    print(\"Đang tải từ điển Tiếng Việt chuẩn...\")\n",
    "    response = requests.get(URL_VIETNAMESE_DICT)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        vietnamese_vocab = set(\n",
    "            line.strip().lower()\n",
    "            for line in response.text.splitlines()\n",
    "            if line.strip()\n",
    "        )\n",
    "        print(f\"-> Đã nạp {len(vietnamese_vocab)} từ vựng chuẩn.\")\n",
    "    else:\n",
    "        raise Exception(\"Lỗi tải từ điển.\")\n",
    "\n",
    "    # 2. Đọc file CSV\n",
    "    print(f\"\\nĐang xử lý file '{file_input}'...\")\n",
    "    df = pd.read_csv(file_input, encoding='utf-8-sig')\n",
    "\n",
    "    # Kiểm tra xem file có cột 'source' không\n",
    "    if 'source' not in df.columns:\n",
    "        raise Exception(\"File CSV không có cột 'source'. Vui lòng kiểm tra lại.\")\n",
    "\n",
    "    # Tên cột chứa từ ngữ (giả sử là cột đầu tiên nếu không phải tên là 'hanviet')\n",
    "    col_word = 'hanviet' if 'hanviet' in df.columns else df.columns[0]\n",
    "\n",
    "    print(f\"-> Tổng số dòng ban đầu: {len(df)}\")\n",
    "\n",
    "    # 3. Hàm logic lọc (CORE LOGIC)\n",
    "    def should_keep_row(row):\n",
    "        word = str(row[col_word]).strip().lower()\n",
    "        source = str(row['source']).strip()\n",
    "\n",
    "        # LOGIC 1: Nếu source KHÁC 'phongp-hanviet-pinyin' -> Luôn giữ lại (True)\n",
    "        if source != target_source:\n",
    "            return True\n",
    "\n",
    "        # LOGIC 2: Nếu source LÀ 'phongp-hanviet-pinyin'\n",
    "        # Chỉ giữ lại nếu từ này KHÔNG nằm trong từ điển phổ thông\n",
    "        # (Nghĩa là xóa nếu nó là từ phổ thông)\n",
    "        is_common_word = word in vietnamese_vocab\n",
    "        if is_common_word:\n",
    "            return False # XÓA\n",
    "        else:\n",
    "            return True  # GIỮ (Vì là từ hiếm/lạ)\n",
    "\n",
    "    # 4. Áp dụng\n",
    "    # axis=1 nghĩa là quét theo từng hàng\n",
    "    mask = df.apply(should_keep_row, axis=1)\n",
    "    df_filtered = df[mask]\n",
    "\n",
    "    # 5. Thống kê và Lưu\n",
    "    so_luong_xoa = len(df) - len(df_filtered)\n",
    "\n",
    "    df_filtered.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"ĐÃ HOÀN TẤT!\")\n",
    "    print(f\"Số từ bị xóa: {so_luong_xoa}\")\n",
    "    print(f\"(Chỉ xóa các từ thuộc source '{target_source}' và trùng với từ điển phổ thông)\")\n",
    "    print(f\"Số dòng còn lại: {len(df_filtered)}\")\n",
    "    print(f\"File kết quả: {output_file}\")\n",
    "\n",
    "    # In ví dụ kiểm chứng\n",
    "    if so_luong_xoa > 0:\n",
    "        print(\"\\nVí dụ các dòng bị xóa:\")\n",
    "        deleted_rows = df[~mask].head(5)\n",
    "        print(deleted_rows[[col_word, 'source']])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi: {e}\")"
   ],
   "id": "1d7c4bd3dac056aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tải từ điển Tiếng Việt chuẩn...\n",
      "-> Đã nạp 72535 từ vựng chuẩn.\n",
      "\n",
      "Đang xử lý file 'hanviet_dictionary.csv'...\n",
      "-> Tổng số dòng ban đầu: 16631\n",
      "\n",
      "========================================\n",
      "ĐÃ HOÀN TẤT!\n",
      "Số từ bị xóa: 10223\n",
      "(Chỉ xóa các từ thuộc source 'phongp-hanviet-pinyin' và trùng với từ điển phổ thông)\n",
      "Số dòng còn lại: 6408\n",
      "File kết quả: han_viet_filtered.csv\n",
      "\n",
      "Ví dụ các dòng bị xóa:\n",
      "     hanviet                 source\n",
      "5101  thướng  phongp-hanviet-pinyin\n",
      "5102  thượng  phongp-hanviet-pinyin\n",
      "5103      cơ  phongp-hanviet-pinyin\n",
      "5104      kỳ  phongp-hanviet-pinyin\n",
      "5105   trung  phongp-hanviet-pinyin\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lọc từ tiếng việt chuẩn ra khỏi ten_rieng.csv",
   "id": "987f3b921dc4e292"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T12:43:31.306513Z",
     "start_time": "2026-01-03T12:43:30.474282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# ==============================================================================\n",
    "# CẤU HÌNH\n",
    "# ==============================================================================\n",
    "file_input = 'ten_rieng.csv'             # File đầu vào\n",
    "output_file = 'ten_rieng_no_common.csv'  # File kết quả\n",
    "\n",
    "# Link từ điển tiếng Việt chuẩn\n",
    "URL_VIETNAMESE_DICT = \"https://raw.githubusercontent.com/duyet/vietnamese-wordlist/master/Viet74K.txt\"\n",
    "\n",
    "try:\n",
    "    print(\"1. Đang tải từ điển Tiếng Việt chuẩn...\")\n",
    "    response = requests.get(URL_VIETNAMESE_DICT)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Nạp từ điển vào Set\n",
    "        vietnamese_vocab = set(\n",
    "            line.strip().lower()\n",
    "            for line in response.text.splitlines()\n",
    "            if line.strip()\n",
    "        )\n",
    "        print(f\"-> Đã nạp thành công: {len(vietnamese_vocab)} từ vựng chuẩn.\")\n",
    "    else:\n",
    "        raise Exception(\"Không tải được từ điển online.\")\n",
    "\n",
    "    print(f\"\\n2. Đang đọc file '{file_input}'...\")\n",
    "    df = pd.read_csv(file_input, encoding='utf-8-sig')\n",
    "    col_name = df.columns[0]\n",
    "\n",
    "    print(f\"-> Tổng số dòng ban đầu: {len(df)}\")\n",
    "\n",
    "    # 3. Định nghĩa hàm XỬ LÝ KÉP (Vừa lọc, vừa phân loại)\n",
    "    def process_name(row):\n",
    "        name = str(row[col_name]).strip()\n",
    "        name_lower = name.lower()\n",
    "\n",
    "        # BƯỚC A: Kiểm tra xem có phải từ phổ thông không\n",
    "        if name_lower in vietnamese_vocab:\n",
    "            return \"DELETE\" # Đánh dấu để xóa\n",
    "\n",
    "        # BƯỚC B: Nếu không phải từ phổ thông -> Phân loại\n",
    "        if ' ' in name: # Nếu có khoảng trắng -> Là cụm từ\n",
    "            return \"phrase\"\n",
    "        else:           # Không có khoảng trắng -> Là từ đơn\n",
    "            return \"word\"\n",
    "\n",
    "    # 4. Áp dụng logic\n",
    "    # Tạo một cột tạm thời 'type' để lưu kết quả phân loại\n",
    "    df['type'] = df.apply(process_name, axis=1)\n",
    "\n",
    "    # 5. Tách dữ liệu\n",
    "    # Chỉ lấy những dòng không bị đánh dấu DELETE\n",
    "    df_clean = df[df['type'] != \"DELETE\"].copy()\n",
    "\n",
    "    # Tính toán số lượng đã xóa\n",
    "    so_luong_xoa = len(df) - len(df_clean)\n",
    "\n",
    "    # 6. Lưu file (Kèm theo cột type để bạn dễ quản lý)\n",
    "    # File sẽ có dạng: teen_code | type (word/phrase)\n",
    "    df_clean.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"HOÀN TẤT!\")\n",
    "    print(f\"Số lượng bị xóa (trùng từ điển): {so_luong_xoa}\")\n",
    "    print(f\"Số tên riêng còn lại: {len(df_clean)}\")\n",
    "\n",
    "    # Thống kê chi tiết\n",
    "    count_word = len(df_clean[df_clean['type'] == 'word'])\n",
    "    count_phrase = len(df_clean[df_clean['type'] == 'phrase'])\n",
    "    print(f\"-> Trong đó: {count_word} từ đơn (word) và {count_phrase} cụm từ (phrase)\")\n",
    "\n",
    "    print(f\"File kết quả: {output_file}\")\n",
    "\n",
    "    # Ví dụ bị xóa\n",
    "    if so_luong_xoa > 0:\n",
    "        print(\"\\nVí dụ các từ bị xóa (Common words):\")\n",
    "        print(df[df['type'] == \"DELETE\"][col_name].head(5).tolist())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi: {e}\")"
   ],
   "id": "f830dbb1b68a3fb8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Đang tải từ điển Tiếng Việt chuẩn...\n",
      "-> Đã nạp thành công: 72535 từ vựng chuẩn.\n",
      "\n",
      "2. Đang đọc file 'ten_rieng.csv'...\n",
      "-> Tổng số dòng ban đầu: 9181\n",
      "\n",
      "========================================\n",
      "HOÀN TẤT!\n",
      "Số lượng bị xóa (trùng từ điển): 1786\n",
      "Số tên riêng còn lại: 7395\n",
      "-> Trong đó: 1920 từ đơn (word) và 5475 cụm từ (phrase)\n",
      "File kết quả: ten_rieng_no_common.csv\n",
      "\n",
      "Ví dụ các từ bị xóa (Common words):\n",
      "['Trưng', 'Á Châu', 'A Di Đà Phật', 'Á Đông', 'Ái']\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
